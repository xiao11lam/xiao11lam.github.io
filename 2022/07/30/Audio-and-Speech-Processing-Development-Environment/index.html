<!DOCTYPE html>
<html lang="en">
  <!-- Head tag -->
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Title -->
  
  <title>Audio and Speech Processing Development Environment - Xiao Zhang (Software Design Office)</title>

  <!--Favicon-->
  <link rel="icon" href="favicon/favicon.ico">

  <!--Description-->
  
      <meta name="description" content="Docker1docker-compose build



1systemctl start docker



1systemctl enable docker



1sudo systemctl stop docker

If there is warning like: Warning: ">
  

  <!--Author-->
  
      <meta name="author" content="Xiao Zhang">
  

  <!-- Pure CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/css/bootstrap.min.css" integrity="sha384-rwoIResjU2yc3z8GV/NPeZWAv56rSmLldC3R/AZzGRnGxQQKnKkoFVhFQhNUwEyJ" crossorigin="anonymous">
  <link href="https://fonts.googleapis.com/css?family=Crimson+Text|Open+Sans:300,800" rel="stylesheet">

  <!-- Custom CSS -->
  
<link rel="stylesheet" href="/css/styles.css">


  <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
  <![endif]-->

  <!-- Google Analytics -->
  

<meta name="generator" content="Hexo 6.2.0"></head>


  <body>
  	<div class="container-fluid navbar-container m-sm-5">
      <!-- Header -->
      <nav class="navbar navbar-toggleable-sm navbar-light px-1 py-3 my-3 mb-sm-5">
  <a class="navbar-brand ml-2" href="/">Xiao Zhang (Software Design Office)</a>
  <button class="navbar-toggler navbar-toggler-right py-2" type="button" data-toggle="collapse" data-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse text-center" id="navbarCollapse">
    <ul class="navbar-nav ml-auto my-auto">
      
        <li class="nav-item">
          <a class="nav-link" href="/about">About</a>
        </li>
      
        <li class="nav-item">
          <a class="nav-link" target="_blank" rel="noopener" href="https://www.linkedin.com/in/xiao-zhang-28785b19b/">LinkedIn</a>
        </li>
      
    </ul>
    <hr class="hidden-md-up" />
  </div>
</nav>


  		<div class="row">
  			<!-- <div class="col-12 mb-4"> -->
<!--   <img class="img-fluid project-img" src="/" alt="Audio and Speech Processing Development Environment"> -->
<!-- </div> -->
<!-- <div class="col-lg-4 col-12 pt-3 px-4 pr-lg-5"> -->
<!--   <h1>Audio and Speech Processing Development Environment</h1> -->
<!-- </div> -->
<div class="col-lg-8 col-12 pt-lg-3 mb-4 pl-lg-5 px-lg-0 px-4 portfolio-content">
  <h1 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h1><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-compose build</span><br></pre></td></tr></table></figure>



<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl start docker</span><br></pre></td></tr></table></figure>



<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="built_in">enable</span> docker</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl stop docker</span><br></pre></td></tr></table></figure>

<p>If there is warning like: Warning: Stopping docker.service, but it can still be activated by:**</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker.socket**</span><br></pre></td></tr></table></figure>



<p>So we can stop the socket</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl stop docker.socket</span><br></pre></td></tr></table></figure>



<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="built_in">enable</span> docker</span><br></pre></td></tr></table></figure>



<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure>



<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker-compose up</span><br></pre></td></tr></table></figure>



<p>项目中架起docker环境</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker system prune</span><br></pre></td></tr></table></figure>





<h1 id="Cuda"><a href="#Cuda" class="headerlink" title="Cuda"></a>Cuda</h1><p><img src="/../images/image-20220730154010169.png" alt="image-20220730154010169"></p>
<h2 id="nvidia-smi"><a href="#nvidia-smi" class="headerlink" title="nvidia-smi"></a>nvidia-smi</h2><p><img src="/../images/image-20220801144443432.png" alt="image-20220801144443432"></p>
<p><strong>Issue 1:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">NVIDIA-SMI has failed because it couldn&#x27;t communicate with the NVIDIA driver. </span><br><span class="line">Make sure that the latest NVIDIA driver is installed and running.</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install dkms</span><br><span class="line">sudo dkms install -m nvidia -v 418.87.00  <span class="comment"># replace the result from ls /usr/src | grep nvidia</span></span><br></pre></td></tr></table></figure>

<p>Check  the NVIDIA number:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls /usr/src | grep nvidia     </span><br></pre></td></tr></table></figure>

<p>This will solve this common issue.</p>
<p><strong>Install the CONDA for WSL2</strong></p>
<p>Please follow this link:<a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/wsl-user-guide/index.html">https://docs.nvidia.com/cuda/wsl-user-guide/index.html</a></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin</span><br><span class="line">sudo <span class="built_in">mv</span> cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600</span><br><span class="line">wget https://developer.download.nvidia.com/compute/cuda/11.7.0/local_installers/cuda-repo-wsl-ubuntu-11-7-local_11.7.0-1_amd64.deb</span><br><span class="line">sudo dpkg -i cuda-repo-wsl-ubuntu-11-7-local_11.7.0-1_amd64.deb</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get -y install cuda</span><br></pre></td></tr></table></figure>

<p>or Installation of Linux x86 CUDA Toolkit using Meta Package:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin</span><br><span class="line">sudo <span class="built_in">mv</span> cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600</span><br><span class="line">wget https://developer.download.nvidia.com/compute/cuda/11.7.0/local_installers/cuda-repo-ubuntu2004-11-7-local_11.7.0-515.43.04-1_amd64.deb</span><br><span class="line">sudo dpkg -i cuda-repo-ubuntu2004-11-7-local_11.7.0-515.43.04-1_amd64.deb</span><br><span class="line">wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-keyring_1.0-1_all.deb</span><br><span class="line">sudo dpkg -i cuda-keyring_1.0-1_all.deb</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get -y install cuda-toolkit-11-7</span><br></pre></td></tr></table></figure>

<p>Check the environment by:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvcc -V</span><br></pre></td></tr></table></figure>

<p>If there is <code>nvida</code> not found, it should be the environmental problem:</p>
<p>Set the environmenal Inside of the .bashrc file, update the path as follows:<br><code> export PATH=&quot;/usr/local/cuda-11.7/bin:$PATH&quot;</code><br><code> export LD_LIBRARY_PATH=&quot;/usr/local/cuda-11.7/lib64:$LD_LIBRARY_PATH&quot;</code></p>
<p><strong>Check the nvidia-smi:</strong></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure>

<p><img src="/../images/image-20220918124124743.png" alt="image-20220918124124743"></p>
<h2 id="WSL"><a href="#WSL" class="headerlink" title="WSL"></a>WSL</h2><p><strong>Check the version of wsl</strong></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wsl -l -v</span><br></pre></td></tr></table></figure>



<p><strong>Update from wsl 1 to wsl2</strong></p>
<p>change the default version into wsl2. </p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wsl --set-default-version 2</span><br></pre></td></tr></table></figure>



<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wsl.exe --set-version Ubuntu 2</span><br></pre></td></tr></table></figure>



<h1 id="Anaconda"><a href="#Anaconda" class="headerlink" title="Anaconda"></a>Anaconda</h1><p>This will show how to install the anaconda at the Ubuntu system:</p>
<p>The first step should be <code>wget</code> the downloaded file:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget https://repo.anaconda.com/archive/Anaconda3-2022.05-Linux-x86_64.sh</span><br><span class="line"><span class="comment"># after we downloaded the Linux Version anaconda, we need to run the .sh file, and we just choose yes</span></span><br><span class="line">sh Anaconda3-2022.05-Linux-x86_64.sh</span><br></pre></td></tr></table></figure>

<p>If  there is a <code>conda not found</code> problem, we need to fix the environmental variables:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># check the bashrc file</span></span><br><span class="line">vi ~/.bashrc</span><br><span class="line"></span><br><span class="line"><span class="comment"># insert the path loc</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:/root/anaconda3/bin/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># excecute file, the conda can be found</span></span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br><span class="line"></span><br><span class="line"><span class="comment"># or we can set the environment into true</span></span><br><span class="line">conda config --<span class="built_in">set</span> auto_activate_base <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<h2 id="Create-a-Python-Env"><a href="#Create-a-Python-Env" class="headerlink" title="Create a Python Env"></a>Create a Python Env</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create a conda env name &quot;env_name&quot;</span></span><br><span class="line">conda create -n env_name python=3.8</span><br><span class="line"></span><br><span class="line"><span class="comment"># activate the env</span></span><br><span class="line">conda activate env_name</span><br><span class="line"></span><br><span class="line"><span class="comment"># deactivate the env</span></span><br><span class="line">conda deactivate env_name</span><br><span class="line"></span><br><span class="line"><span class="comment"># create a conda env with environment.yml</span></span><br><span class="line">conda <span class="built_in">env</span> create --name env_name -f environment.yml</span><br><span class="line"></span><br><span class="line"><span class="comment"># update the conda env with environment.yml</span></span><br><span class="line">conda <span class="built_in">env</span> update --name <span class="variable">$MYENV</span> -f environment.yml</span><br></pre></td></tr></table></figure>

<h2 id="Environment-yml"><a href="#Environment-yml" class="headerlink" title="Environment.yml"></a>Environment.yml</h2><p>This is an example of <code>environmental.yml</code> from <code>shennong</code> package.<a target="_blank" rel="noopener" href="https://docs.cognitive-ml.fr/shennong/index.html">https://docs.cognitive-ml.fr/shennong/index.html</a></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">name: shennong</span><br><span class="line">channels:</span><br><span class="line">  - conda-forge</span><br><span class="line">  - coml</span><br><span class="line">dependencies:</span><br><span class="line">  - python&gt;=3.6</span><br><span class="line">  - shennong-pykaldi</span><br><span class="line">  - ffmpeg</span><br><span class="line">  - h5features&gt;=1.3.2</span><br><span class="line">  - h5py&lt;3.0  <span class="comment"># because h5features supports only h5py-2.*</span></span><br><span class="line">  - hmmlearn&gt;=0.2.0,&lt;0.3.0</span><br><span class="line">  - joblib</span><br><span class="line">  <span class="comment"># shennong-pykaldi is compiled on numpy-1.15, so shennong must stay on the</span></span><br><span class="line">  <span class="comment"># 1.15 version</span></span><br><span class="line">  - numpy==1.15.*</span><br><span class="line">  - pip</span><br><span class="line">  - pydub</span><br><span class="line">  - pytest&gt;=5.0</span><br><span class="line">  - pytest-cov</span><br><span class="line">  - pytest-runner</span><br><span class="line">  - pyyaml</span><br><span class="line">  - scipy</span><br><span class="line">  - sox  <span class="comment"># sox binary</span></span><br><span class="line">  - sphinx</span><br><span class="line">  - sphinx_rtd_theme</span><br><span class="line">  - tensorflow&lt;2.5</span><br><span class="line">  - pip:</span><br><span class="line">      - json-tricks==3.15.*</span><br><span class="line">      - sox  <span class="comment"># pysox</span></span><br></pre></td></tr></table></figure>







<h1 id="Pytorch"><a href="#Pytorch" class="headerlink" title="Pytorch"></a>Pytorch</h1><h2 id="Install-Pytorch"><a href="#Install-Pytorch" class="headerlink" title="Install Pytorch"></a>Install Pytorch</h2><p>We need to install the pytorch:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install pytorch</span><br></pre></td></tr></table></figure>



<h2 id="Check-the-Version-of-the-Pytorch"><a href="#Check-the-Version-of-the-Pytorch" class="headerlink" title="Check the Version of the Pytorch"></a>Check the Version of the Pytorch</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Torch version:&quot;</span>, torch.__version__)</span><br></pre></td></tr></table></figure>





<h1 id="Heroku"><a href="#Heroku" class="headerlink" title="Heroku"></a>Heroku</h1><p>Create a heroku server.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">heroku create</span><br></pre></td></tr></table></figure>

<p>Push the original codes into the empty projects.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push heroku HEAD:master</span><br></pre></td></tr></table></figure>





<h1 id="Linux-Environment"><a href="#Linux-Environment" class="headerlink" title="Linux Environment"></a>Linux Environment</h1><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># from https://github.com/kaldi-asr/kaldi/issues/515 @ willendzw</span></span><br><span class="line"><span class="comment"># The env.sh is not under tools/extras/. It is under tools/. So you just need to</span></span><br><span class="line"><span class="built_in">source</span> env.sh. It just add irstlm path. Eg:</span><br><span class="line"><span class="built_in">export</span> IRSTLM=/home/willen/Documents/kaldi/kaldi/tools/irstlm</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$&#123;PATH&#125;</span>:<span class="variable">$&#123;IRSTLM&#125;</span>/bin</span><br></pre></td></tr></table></figure>



<h3 id="AWS-Ubuntu-EC2"><a href="#AWS-Ubuntu-EC2" class="headerlink" title="AWS Ubuntu EC2"></a>AWS Ubuntu EC2</h3><p><img src="/../images/image-20220918004648297.png" alt="image-20220918004648297"></p>
<p>We can use the AWS and install it by this video tutorial: <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=NuB2BTYNosE&amp;t=81s">https://www.youtube.com/watch?v=NuB2BTYNosE&amp;t=81s</a></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Connect the ec2 server to ssh</span></span><br><span class="line">ssh -i ...pem ubuntu@Public IPv4 DNS copied <span class="comment"># if you are using ubuntu please change the username &quot;ec2-user&quot; into &quot;ubuntu&quot;, otherwise just it.</span></span><br><span class="line">ssh -i xiao.pem ec2-user@ec2-3-248-220-97.eu-west-1.compute.amazonaws.com</span><br></pre></td></tr></table></figure>





<h1 id="Librosa"><a href="#Librosa" class="headerlink" title="Librosa"></a>Librosa</h1><p>Here is the scripts that installed in case that it will be facing the incompatibale issues for librosa installing.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda install -c numba numba</span><br><span class="line"></span><br><span class="line">conda install -c conda-forge librosa</span><br></pre></td></tr></table></figure>

<p>Here is one example:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> scipy</span><br><span class="line"><span class="keyword">import</span> librosa</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">y, sr = librosa.load(<span class="string">&quot;/mnt/c/Users/ABC/SPTK/egs/analysis_synthesis/lpc/data.org.wav&quot;</span>, duration=<span class="number">0.020</span>)</span><br><span class="line"></span><br><span class="line">a = librosa.lpc(y, order=<span class="number">4</span>)</span><br><span class="line">b = np.hstack([[<span class="number">0</span>], -<span class="number">1</span> * a[<span class="number">1</span>:]])</span><br><span class="line"></span><br><span class="line">y_hat = scipy.signal.lfilter(b, [<span class="number">1</span>], y)</span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.plot(y)</span><br><span class="line">ax.plot(y_hat, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">ax.legend([<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;y_hat&#x27;</span>])</span><br><span class="line">ax.set_title(<span class="string">&#x27;LP Model Forward Prediction&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.savefig(<span class="string">&quot;out.png&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>The saved png file can be looks like that:</p>
<p><img src="/../images/out.png" alt="out"></p>
<p>Here is a very good tutorials to express the librosa in the speech recognition and processing tasks:</p>
<p><a target="_blank" rel="noopener" href="https://medium.com/wavey-ai/end-to-end-speech-recognition-f13f0d0197c7">https://medium.com/wavey-ai/end-to-end-speech-recognition-f13f0d0197c7</a></p>

</div>


<style>
  .portfolio-content img {
    width: 100%;      /* Make the image width equal to the container width */
    height: auto;     /* Maintain the aspect ratio */
    max-width: 100%;  /* Ensures the image does not exceed the container width */
  }
</style>





      </div>
      
  	</div>

    <!-- After footer scripts -->
    <script src="https://code.jquery.com/jquery-3.1.1.slim.min.js" integrity="sha384-A7FZj7v+d/sdmMqp/nOQwliLvUsJfDHW+k9Omg/a/EheAdgtzNs3hpfag6Ed950n" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.4.0/js/tether.min.js" integrity="sha384-DztdAPBWPRXSA/3eYEEUWrWCy7G5KFbe8fFjk5JAIxUYHKkDx6Qin1DkWx51bBrb" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/js/bootstrap.min.js" integrity="sha384-vBWWzlZJ8ea9aCX4pEW3rVHjgjt7zpkNpZk+02D9phzyeVkE+jo0ieGizqPLForn" crossorigin="anonymous"></script>

  </body>
</html>
