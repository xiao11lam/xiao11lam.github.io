

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Xiao Zhang">
  <meta name="keywords" content="Speech and Language Processing">
  
    <meta name="description" content="Audio ProcessingADC (Analog to Digital Codec) After the Microphone got the analog signals from the environment, it will pass through the codec and transform it into the digital data which only has “0”">
<meta property="og:type" content="article">
<meta property="og:title" content="Audio and speech Processing Theory">
<meta property="og:url" content="http://xiaos.site/2022/08/30/Audio-and-speech-Processing-Theory/index.html">
<meta property="og:site_name" content="Xiao @ Speech and Language Processing">
<meta property="og:description" content="Audio ProcessingADC (Analog to Digital Codec) After the Microphone got the analog signals from the environment, it will pass through the codec and transform it into the digital data which only has “0”">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://xiaos.site/images/image-20220830190323321.png">
<meta property="og:image" content="http://xiaos.site/images/image-20220917181359913.png">
<meta property="og:image" content="http://xiaos.site/images/image-20220917174531894.png">
<meta property="og:image" content="http://xiaos.site/images/image-20220917175421567.png">
<meta property="og:image" content="http://xiaos.site/images/image-20220917175904984.png">
<meta property="og:image" content="http://xiaos.site/images/image-20220917180023833.png">
<meta property="og:image" content="http://xiaos.site/images/image-20220917180656489.png">
<meta property="og:image" content="http://xiaos.site/images/image-20220917181019732.png">
<meta property="og:image" content="http://xiaos.site/images/image-20220917181123310.png">
<meta property="og:image" content="http://xiaos.site/images/image-20220917181318336.png">
<meta property="og:image" content="http://xiaos.site/images/image-20220919014841416.png">
<meta property="og:image" content="http://xiaos.site/images/image-20220919015020116.png">
<meta property="og:image" content="http://xiaos.site/images/image-20220919015035225.png">
<meta property="og:image" content="http://xiaos.site/images/image-20220919015237395.png">
<meta property="og:image" content="http://xiaos.site/images/image-20220830144931149.png">
<meta property="article:published_time" content="2022-08-30T13:19:00.000Z">
<meta property="article:modified_time" content="2022-09-19T00:55:08.542Z">
<meta property="article:author" content="Xiao Zhang">
<meta property="article:tag" content="Speech and Language Processing">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://xiaos.site/images/image-20220830190323321.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>Audio and speech Processing Theory - Xiao @ Speech and Language Processing</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="/css/fluid-extention.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"xiaos.site","root":"/","version":"1.9.1","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>

  
<meta name="generator" content="Hexo 6.2.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Xiao @ Speech and Language Processing</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                Home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archive/">
                <i class="iconfont icon-archive-fill"></i>
                Archive
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/products/">
                <i class="iconfont icon-category-fill"></i>
                Products
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                Use Cases
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                About
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                Links
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/banner.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Audio and speech Processing Theory"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-08-30 14:19" pubdate>
          August 30, 2022 pm
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          6.6k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          56 mins
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Audio and speech Processing Theory</h1>
            
            <div class="markdown-body">
              
              <h1 id="Audio-Processing"><a href="#Audio-Processing" class="headerlink" title="Audio Processing"></a>Audio Processing</h1><h2 id="ADC-Analog-to-Digital-Codec"><a href="#ADC-Analog-to-Digital-Codec" class="headerlink" title="ADC (Analog to Digital Codec)"></a>ADC (Analog to Digital Codec)</h2><p><img src="/../images/image-20220830190323321.png" srcset="/img/loading.gif" lazyload alt="https://www.rfwireless-world.com/Terminology/Advantages-and-Disadvantages-of-Pulse-Density-Modulation.html"></p>
<p>After the Microphone got the analog signals from the environment, it will pass through the codec and transform it into the digital data which only has “0”, and “1”. </p>
<p>The signals that continually trace the same path in this way are called periodic. </p>
<p>The shape that repeats is called a <strong>cycle</strong>, and the time it takes to repeat is called the <strong>period</strong>.</p>
<p>$$<br>f &#x3D; \frac{1}{p}<br>(f: freq, p: period)\<br>f &#x3D; rate * channel.num * sample.bits<br>$$</p>
<p>$$<br>dur(sec) &#x3D; \frac{bit.num}{bit&#x2F;sec}<br>$$</p>
<p>$$<br>dur(sec) &#x3D; \frac{size(mb) * 8 * 1024 * 1024}{sample.rate * bit.depth * channel.num }<br>$$<br>If there is 16 bit mono speech file:<br>$$<br>dur(sec) &#x3D; \frac{size(mb) * 8 * 1024 * 1024}{sample.rate * 16 * 1 }<br>$$</p>
<p>The sawtooth waveform is important in the study of production, as the vocal cords change the airflow from the lungs into a signal that looks similar to a sawtooth.</p>
<p>Square wave, or rectangle wave, or pulse trains. The signals differ in how long they stay at the top and bottom of their travel, their duty cycle (the proportion of period in which they are at their maximum).</p>
<p>Each of these lasts for a short time only, and hence they are known as <strong>transients</strong> (since they don’t hang around). <strong>Burst</strong> is happened in the human speech and they are part of the transients.</p>
<p>The rms amplitude is the most important way of specifying the amplitude of a signal because it presupposes the use of a related quantity - <strong>intensity</strong>.</p>
<p><a target="_blank" rel="noopener" href="http://soundfile.sapp.org/doc/WaveFormat/">http://soundfile.sapp.org/doc/WaveFormat/</a></p>
<h2 id="Audio-Architecture"><a href="#Audio-Architecture" class="headerlink" title="Audio Architecture"></a>Audio Architecture</h2><p>We will use the <code>SDL</code> C++ lib package to explain this, and we will know from this that how computer render the audio files.</p>
<p>The most high level concept or the interface of the audio system from the <code>SDL</code> is the <code>IAudioContext</code>. </p>
<h4 id="IAudioContext"><a href="#IAudioContext" class="headerlink" title="IAudioContext"></a>IAudioContext</h4><p>The <code>IAudioConext</code> contains those operations:</p>
<figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs scss">-<span class="hljs-attr">--playAudio</span> (AudioObject)<br>-<span class="hljs-attr">--PauseAudio</span> (AudioObject)<br>-<span class="hljs-attr">--StopAudio</span> (AudioObject)<br></code></pre></td></tr></table></figure>

<p>Another component is like <code>IAudioDevice</code>, it includes:</p>
<figure class="highlight isbl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs isbl">---<span class="hljs-function"><span class="hljs-title">CreateAudio</span>(<span class="hljs-variable">fileName</span>)</span><br>---<span class="hljs-function"><span class="hljs-title">ReleaseAudio</span>(<span class="hljs-variable">IAudioData</span>)</span><br></code></pre></td></tr></table></figure>

<p>We will also have an abstract idea, like there has <code>AudioObject</code>. This is the object of our audio system.</p>
<p>It includes:</p>
<figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs scss"><span class="hljs-built_in">---GenerateSamples</span>(stream, len)<br><span class="hljs-built_in">---SetPos</span>(pos) # set the <span class="hljs-attribute">position</span> of the <span class="hljs-selector-tag">audio</span> rendering<br>-<span class="hljs-attr">--SampleInfo</span><br>----<span class="hljs-attr">--volume</span><br>----<span class="hljs-attr">--pitch</span><br>----<span class="hljs-attr">--loopLoc</span><br>----<span class="hljs-attr">--Panning</span><br>-<span class="hljs-attr">--IAudioData</span><br></code></pre></td></tr></table></figure>

<p>We got <code>IAudioData</code> to contain the audio data, they are generated from: <code>GenerateSamples(stream, len, Pos, SampleInfo)</code>.</p>
<h1 id="Speech-and-Language-Processing"><a href="#Speech-and-Language-Processing" class="headerlink" title="Speech and Language Processing"></a>Speech and Language Processing</h1><p>Here are the lifecycle of the speech features processing.</p>
<p><img src="/../images/image-20220917181359913.png" srcset="/img/loading.gif" lazyload alt="image-20220917181359913"></p>
<h2 id="Short-time-analysis-Speech-Features"><a href="#Short-time-analysis-Speech-Features" class="headerlink" title="Short time analysis : Speech Features"></a>Short time analysis : Speech Features</h2><p>The feature in speech means that <code>an indivisual measurable property or characteristics of a phenomenon being observed.</code></p>
<p>The three principles of a good feature:</p>
<figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">Informative   </span><br><span class="hljs-attribute">Discriminating</span><br><span class="hljs-attribute">Independent</span><br></code></pre></td></tr></table></figure>



<h3 id="Short-time-analysis"><a href="#Short-time-analysis" class="headerlink" title="Short time analysis"></a>Short time analysis</h3><p>The basic idea is to break the audio frames into small trunks, which range from <code>10ms ~ 30ms</code>, so we will think in a more micro way. In this way, each trunk will be stationary. And those trunks we will call it <code>frames</code>.  In video processing, each image you captured is a frame, but in speech processing, we will only know the <strong>dense samples</strong> since we only use the <code>frame</code> for analyzing. </p>
<h4 id="Framing"><a href="#Framing" class="headerlink" title="Framing"></a>Framing</h4><p><img src="/../images/image-20220917174531894.png" srcset="/img/loading.gif" lazyload alt="image-20220917174531894"></p>
<p>There are two concepts from the framing:</p>
<ol>
<li>frame size: the duration of each frame</li>
<li>frame step&#x2F;stride: the temporal distance between two consecutive frames</li>
</ol>
<p>Three principles of framing:</p>
<ol>
<li>Size &gt; Step (Mostly used way, so they can share overlaps)</li>
<li>Size &#x3D; Step (So each sampling point only belongs to a specific frame)</li>
<li>Size &lt; Step (So there may have gaps between different frames, which is not suggested since it can lose some info)</li>
</ol>
<p>Eg:</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">1</span> sec audio file with <span class="hljs-number">16</span>KHz sample rate, frame size: <span class="hljs-number">25</span>ms, frame step(stride): <span class="hljs-number">10</span>ms<br><br><span class="hljs-attribute">Nums_frames</span> = <span class="hljs-number">1</span> second/ <span class="hljs-number">10</span>ms = <span class="hljs-number">100</span><br><span class="hljs-attribute">Nums_samples</span> per frame: <span class="hljs-number">16</span> KHz * <span class="hljs-number">0</span>.<span class="hljs-number">025</span>s = <span class="hljs-number">400</span><br><br></code></pre></td></tr></table></figure>



<h4 id="Window-function"><a href="#Window-function" class="headerlink" title="Window function"></a>Window function</h4><p><img src="/../images/image-20220917175421567.png" srcset="/img/loading.gif" lazyload alt="image-20220917175421567"></p>
<p>In order to solve the framing discontinuity problem, we need to use the windowing function. Because when we do the framing, it will make the original speech signal with no boundary connections, which can cause discontinuity (Gibbs Phenomenon: <strong>undesired high frequency components</strong> and <strong>spectral leakage</strong>). </p>
<p>The logic of the windowing function is to give each frame a weight, near the edge values we make it <strong>close to 0</strong>, if in the middle frame, we keep it untouched. <img src="/../images/image-20220917175904984.png" srcset="/img/loading.gif" lazyload alt="image-20220917175904984"></p>
<h5 id="Gaussian-Windowing"><a href="#Gaussian-Windowing" class="headerlink" title="Gaussian Windowing"></a>Gaussian Windowing</h5><h5 id="Hanning-Windowing-amp-Hamming-Windowing"><a href="#Hanning-Windowing-amp-Hamming-Windowing" class="headerlink" title="Hanning Windowing &amp; Hamming Windowing"></a>Hanning Windowing &amp; Hamming Windowing</h5><p><img src="/../images/image-20220917180023833.png" srcset="/img/loading.gif" lazyload alt="image-20220917180023833"></p>
<p>Hamming windowing will set the edge totally like close to 0, but hamming window will slightly not that harsh.</p>
<h4 id="Frame-Post-Processing"><a href="#Frame-Post-Processing" class="headerlink" title="Frame Post Processing"></a>Frame Post Processing</h4><p>After we did the framing and the windowing, we need to do some frame post processing.</p>
<p>They includes:</p>
<ol>
<li>Frame Stacking : Stacking the neighboring frames into a single super frame, it will combine the relevant frames into a bigger frame.</li>
</ol>
<p><img src="/../images/image-20220917180656489.png" srcset="/img/loading.gif" lazyload alt="image-20220917180656489"></p>
<p>As shown it will copy each frame from the previous frame, it will help us to know more information from the previous frame. The <code>?</code> frame from the graph can be replaced by 1st frame.</p>
<ol start="2">
<li>Frame Subsampling: Drop some frame.</li>
</ol>
<p>It will help us to reduce the computational cost. </p>
<p><img src="/../images/image-20220917181019732.png" srcset="/img/loading.gif" lazyload alt="image-20220917181019732"></p>
<p>We mostly do the Frame Stacking and then is the Frame Subsampling. </p>
<ol start="3">
<li>Frame Normalization: Optimize the numeric values to follow the Normal Distributions.</li>
</ol>
<p><img src="/../images/image-20220917181123310.png" srcset="/img/loading.gif" lazyload alt="image-20220917181123310"></p>
<p>The normalization parts  helped us to <code>converge</code> when we do the training.</p>
<p><img src="/../images/image-20220917181318336.png" srcset="/img/loading.gif" lazyload alt="image-20220917181318336"></p>
<h3 id="Feature-Extraction"><a href="#Feature-Extraction" class="headerlink" title="Feature Extraction"></a>Feature Extraction</h3><h4 id="Global-Acoustic-Features-Stationary-features"><a href="#Global-Acoustic-Features-Stationary-features" class="headerlink" title="Global Acoustic Features (Stationary features)"></a>Global Acoustic Features (Stationary features)</h4><p>The global acoustic features are mostly stationary features, since we always need to get the whole audio files then can we processing those features.</p>
<p>Also if the speech signal is very <strong>periodic</strong> signal which are very stable, then it is very useful to discuss about those global acoustic features. But to many speech signals they are not periodic, if we use the stationary features to describe the whole speech signal, which will <strong>lose some details of the speech</strong>. And another question could be, the stationary features will be extremely sensible to the <strong>noise</strong>. </p>
<h5 id="Fundamental-frequency-f0"><a href="#Fundamental-frequency-f0" class="headerlink" title="Fundamental frequency (f0)"></a>Fundamental frequency (f0)</h5><h5 id="Formants-f1-and-f2"><a href="#Formants-f1-and-f2" class="headerlink" title="Formants (f1 and f2)"></a>Formants (f1 and f2)</h5><h5 id="Intensity"><a href="#Intensity" class="headerlink" title="Intensity"></a>Intensity</h5><h3 id="Time-Domain-Features"><a href="#Time-Domain-Features" class="headerlink" title="Time Domain Features"></a>Time Domain Features</h3><p>We can extract the features directly from the waveform without the Fourier transform.</p>
<p>Here are the usual time domain features:</p>
<p><strong>Short Time Energy</strong></p>
<p>It mostly used in VAD, if high energy &#x3D;&gt; speech signal, and in Automatic Gain Control (AGC).</p>
<p><strong>Short Time Average Magnitude</strong></p>
<p><strong>Short-time Zero Cross Rate (ZCR)</strong></p>
<p><strong>Short-time Autocorrelation</strong></p>
<p>We will delay the signals by k samples, then compute the <code>correlation</code>. </p>
<p><img src="/../images/image-20220919014841416.png" srcset="/img/loading.gif" lazyload alt="image-20220919014841416"></p>
<p>We will mostly use this in the <strong>pitch detection</strong>! </p>
<p><strong>Short-time average magnitude difference function (AMDF)</strong></p>
<p>We will delay the signals by k samples, then compute the <code>difference</code>.</p>
<p><img src="/../images/image-20220919015020116.png" srcset="/img/loading.gif" lazyload alt="image-20220919015020116"> </p>
<p>For the short-time AMDF, we use:</p>
<p><img src="/../images/image-20220919015035225.png" srcset="/img/loading.gif" lazyload alt="image-20220919015035225"></p>
<p>It just like the autocorrelation, but it is very good for the pitch dection. </p>
<p><strong>Short Time Linear Predictive Coding (LPC)</strong></p>
<p>We will assume that each sample can be approximated by previous samples via linear combinations:</p>
<p><img src="/../images/image-20220919015237395.png" srcset="/img/loading.gif" lazyload alt="image-20220919015237395"></p>
<p>$$<br>The \ combination \ of \ the \ previous \ ks \ samples : a_{i} \<br>the \ difference : e[n] \<br>Each \ frame \ has \ N \ Samples<br>$$</p>
<h3 id="Frequency-Domain-Features"><a href="#Frequency-Domain-Features" class="headerlink" title="Frequency Domain Features"></a>Frequency Domain Features</h3><p>We need to do the Fourier transform firstly, and this is always be used. </p>
<h1 id="Speech-Production-Model"><a href="#Speech-Production-Model" class="headerlink" title="Speech Production Model"></a>Speech Production Model</h1><p>The voiced and unvoiced speech mostly for 10~20 ms. </p>
<p><img src="/../images/image-20220830144931149.png" srcset="/img/loading.gif" lazyload alt="Pic From: http://eemedia.ee.unsw.edu.au/contents/elec9344/LectureNotes/Chapter%201.pdf"></p>
<p>The vocal tract model can be understood by a filter equation, here can be the transfer function, the <code>n</code> means the filers you want to have:<br>$$<br>\frac{1}{1 + b_{1}z^{-1} + b_{2}z^{-2} + b_{n}z^{-n} }<br>$$</p>
<p>The Radiation model here means the <code>lip model</code>. </p>
<h1 id="Linguistics-amp-Phonetics"><a href="#Linguistics-amp-Phonetics" class="headerlink" title="Linguistics &amp; Phonetics"></a>Linguistics &amp; Phonetics</h1><p>Linguistics can be a science about hyposis and experimental research. We study human languages as a natural phenomenon, and this is what linguistics about. And linguistics should not used as a mean of discrimination. </p>
<p>From <strong>Panini</strong>, we still use his <strong>level of analysis</strong> study about Sanskrit linguistics:</p>
<ol>
<li>Phonology (Sound Difference for each phone in difference languages)</li>
<li>Morphology (格)</li>
<li>Syntax </li>
<li>Lexicon （like the dictionary)</li>
</ol>
<p><strong>Contemporary linguistics is about unwealing the hidden rules of the languages.</strong></p>
<p>Basically, the system of language and the system of societies and cultures can be analysed in a similar way.  <strong>So its about data so much, it called Structurism.</strong> </p>

              
            </div>
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Audio and speech Processing Theory</div>
      <div>http://xiaos.site/2022/08/30/Audio-and-speech-Processing-Theory/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>Xiao Zhang</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>August 30, 2022</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>Licensed under</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/08/30/Audio-and-Electroacoustic-System-Engineering/" title="Audio and Electroacoustic System Engineering">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Audio and Electroacoustic System Engineering</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/08/29/CMake-for-Audio-and-Speech-Processing/" title="CMake for Audio and Speech Processing">
                        <span class="hidden-mobile">CMake for Audio and Speech Processing</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  <article id="comments" lazyload>
    

  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;Table of Contents</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  








    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>© 2022 By Xiao Zhang</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        Views: 
        <span id="busuanzi_value_site_pv"></span>
        
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        Visitors: 
        <span id="busuanzi_value_site_uv"></span>
        
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  

  

  

  

  

  

  




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script>
  (function() {
    var enableLang = CONFIG.code_language.enable && CONFIG.code_language.default;
    var enableCopy = CONFIG.copy_btn;
    if (!enableLang && !enableCopy) {
      return;
    }

    function getBgClass(ele) {
      return Fluid.utils.getBackgroundLightness(ele) >= 0 ? 'code-widget-light' : 'code-widget-dark';
    }

    var copyTmpl = '';
    copyTmpl += '<div class="code-widget">';
    copyTmpl += 'LANG';
    copyTmpl += '</div>';
    jQuery('.markdown-body pre').each(function() {
      var $pre = jQuery(this);
      if ($pre.find('code.mermaid').length > 0) {
        return;
      }
      if ($pre.find('span.line').length > 0) {
        return;
      }

      var lang = '';

      if (enableLang) {
        lang = CONFIG.code_language.default;
        if ($pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2 && $pre.children().hasClass('hljs')) {
          lang = $pre[0].children[0].classList[1];
        } else if ($pre[0].getAttribute('data-language')) {
          lang = $pre[0].getAttribute('data-language');
        } else if ($pre.parent().hasClass('sourceCode') && $pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2) {
          lang = $pre[0].children[0].classList[1];
          $pre.parent().addClass('code-wrapper');
        } else if ($pre.parent().hasClass('markdown-body') && $pre[0].classList.length === 0) {
          $pre.wrap('<div class="code-wrapper"></div>');
        }
        lang = lang.toUpperCase().replace('NONE', CONFIG.code_language.default);
      }
      $pre.append(copyTmpl.replace('LANG', lang).replace('code-widget">',
        getBgClass($pre[0]) + (enableCopy ? ' code-widget copy-btn" data-clipboard-snippet><i class="iconfont icon-copy"></i>' : ' code-widget">')));

      if (enableCopy) {
        Fluid.utils.createScript('https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js', function() {
          var clipboard = new window.ClipboardJS('.copy-btn', {
            target: function(trigger) {
              var nodes = trigger.parentNode.childNodes;
              for (var i = 0; i < nodes.length; i++) {
                if (nodes[i].tagName === 'CODE') {
                  return nodes[i];
                }
              }
            }
          });
          clipboard.on('success', function(e) {
            e.clearSelection();
            e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-copy', 'icon-success');
            setTimeout(function() {
              e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-success', 'icon-copy');
            }, 2000);
          });
        });
      }
    });
  })();
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        MathJax = {
          tex    : {
            inlineMath: { '[+]': [['$', '$']] }
          },
          loader : {
            load: ['ui/lazy']
          },
          options: {
            renderActions: {
              findScript    : [10, doc => {
                document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                  const display = !!node.type.match(/; *mode=display/);
                  const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                  const text = document.createTextNode('');
                  node.parentNode.replaceChild(text, node);
                  math.start = { node: text, delim: '', n: 0 };
                  math.end = { node: text, delim: '', n: 0 };
                  doc.math.push(math);
                });
              }, '', false],
              insertedScript: [200, () => {
                document.querySelectorAll('mjx-container').forEach(node => {
                  let target = node.parentNode;
                  if (target.nodeName.toLowerCase() === 'li') {
                    target.parentNode.classList.add('has-jax');
                  }
                });
              }, '', false]
            }
          }
        };
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.1/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
