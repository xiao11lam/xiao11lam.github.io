<!DOCTYPE html>
<html lang="en">
  <!-- Head tag -->
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Title -->
  
  <title>A Brief Introduction to the Kaldi ASR Toolkit - Xiao Zhang (Software Design Office)</title>

  <!--Favicon-->
  <link rel="icon" href="favicon/favicon.ico">

  <!--Description-->
  
      <meta name="description" content="1. Acoustic Model: IntroductionAny ASR system can be just divided into three parts: 

Acoustic Model
Language Model
Decoder

Kaldi has a lot of exampl">
  

  <!--Author-->
  
      <meta name="author" content="Xiao Zhang">
  

  <!-- Pure CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/css/bootstrap.min.css" integrity="sha384-rwoIResjU2yc3z8GV/NPeZWAv56rSmLldC3R/AZzGRnGxQQKnKkoFVhFQhNUwEyJ" crossorigin="anonymous">
  <link href="https://fonts.googleapis.com/css?family=Crimson+Text|Open+Sans:300,800" rel="stylesheet">

  <!-- Custom CSS -->
  
<link rel="stylesheet" href="/css/styles.css">


  <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
  <![endif]-->

  <!-- Google Analytics -->
  

<meta name="generator" content="Hexo 6.2.0"></head>


  <body>
  	<div class="container-fluid navbar-container m-sm-5">
      <!-- Header -->
      <nav class="navbar navbar-toggleable-sm navbar-light px-1 py-3 my-3 mb-sm-5">
  <a class="navbar-brand ml-2" href="/">Xiao Zhang (Software Design Office)</a>
  <button class="navbar-toggler navbar-toggler-right py-2" type="button" data-toggle="collapse" data-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse text-center" id="navbarCollapse">
    <ul class="navbar-nav ml-auto my-auto">
      
        <li class="nav-item">
          <a class="nav-link" href="/about">About</a>
        </li>
      
        <li class="nav-item">
          <a class="nav-link" target="_blank" rel="noopener" href="https://www.linkedin.com/in/xiao-zhang-28785b19b/">LinkedIn</a>
        </li>
      
    </ul>
    <hr class="hidden-md-up" />
  </div>
</nav>


  		<div class="row">
  			<!-- <div class="col-12 mb-4"> -->
<!--   <img class="img-fluid project-img" src="/" alt="A Brief Introduction to the Kaldi ASR Toolkit"> -->
<!-- </div> -->
<!-- <div class="col-lg-4 col-12 pt-3 px-4 pr-lg-5"> -->
<!--   <h1>A Brief Introduction to the Kaldi ASR Toolkit</h1> -->
<!-- </div> -->
<div class="col-lg-8 col-12 pt-lg-3 mb-4 pl-lg-5 px-lg-0 px-4 portfolio-content">
  <h1 id="1-Acoustic-Model-Introduction"><a href="#1-Acoustic-Model-Introduction" class="headerlink" title="1. Acoustic Model: Introduction"></a>1. Acoustic Model: Introduction</h1><p>Any ASR system can be just divided into three parts: </p>
<ol>
<li>Acoustic Model</li>
<li>Language Model</li>
<li>Decoder</li>
</ol>
<p>Kaldi has a lot of examples in its projects.There are two necessary raw materials for us to train the model:</p>
<ol>
<li><strong>.wav file</strong></li>
<li><strong>labelled .txt</strong></li>
</ol>
<p>We need four necessary elements in Kaldi! We call it <strong>“HCLG.fst”</strong>, we can make speech recognition from these core file. Acutally, just like we are building a map, and we just decode all the paths from there in order to get the prediction results. The underneath idea just like from the typology from the mathematics.<br>We are using <code>Viterbi</code> algorithm to decoding our <code>HCLG.fst</code>. The exact name should be token passing method, which is a kind of variant algorithm of <code>Viterbi</code>.</p>
<p><img src="/../images/directorystructure2.png" alt="This Pic is from: https://www.eleanorchodroff.com/tutorial/kaldi/training-acoustic-models.html#prepare-directories"></p>
<p>Here are some tutorials for installing the Kaldi in your local machine:	</p>
<p><a target="_blank" rel="noopener" href="https://www.eleanorchodroff.com/tutorial/kaldi/installation.html">https://www.eleanorchodroff.com/tutorial/kaldi/installation.html</a></p>
<p><a target="_blank" rel="noopener" href="https://www.assemblyai.com/blog/kaldi-speech-recognition-for-beginners-a-simple-tutorial/">https://www.assemblyai.com/blog/kaldi-speech-recognition-for-beginners-a-simple-tutorial/</a></p>
<h2 id="1-1-Audio-Corpus"><a href="#1-1-Audio-Corpus" class="headerlink" title="1.1 Audio Corpus"></a>1.1 Audio Corpus</h2><p>In kaldi, 1 frame is 10ms. For some front work, it always like 24ms for one frame. For a workable dataset, we at least need 2000 hrs data. </p>
<h3 id="1-2-1-About-UTF-8"><a href="#1-2-1-About-UTF-8" class="headerlink" title="1.2.1 About UTF-8"></a>1.2.1 About UTF-8</h3><p>Before we really get into the world of Kaldi, we need to know the character decoding and encoding standard. So we need to know the basics of the UTF-8 &amp; Ascii. </p>
<p>As we knew there can be various languages in this world other than English, we need to make it more accesible to encode and then transmit. Different countries can have different kinds of encoding and decoding standards, this can be a big burden of the communication.Thus, people created the UTF-8 to unify the standards in all of the world, so different countries do need to worry about the discontinuity of the language communication.</p>
<p>We can just run this before head into the shell, so we can manipulate the Chinese or any other languages’ characters in Python in linux system.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> PYTHONIOENCODING=utf-8</span><br></pre></td></tr></table></figure>

<p>In UNIX, we can firstly check the file’s encoding format by:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">file ../..txt</span><br></pre></td></tr></table></figure>

<p>If it is UTF-16 Little Endian or other formats, we can just convert it into UTF-8 by:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iconv -l UTF-16LE -t UTF-8 ../.../...</span><br></pre></td></tr></table></figure>

<p>Eg. there has a <strong>dir</strong> with many .txt files in UTF16 which in <em>local&#x2F;data</em>:</p>
<p>Here are the standard manipulation:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># firstly, we make a new dir and make sure put in all the manipulated data in this dir</span></span><br><span class="line"><span class="built_in">mkdir</span> <span class="built_in">local</span>/audio_data_utf8</span><br><span class="line"></span><br><span class="line"><span class="comment"># then we do a loop to put all the data in local/data to local/audio_data_utf8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">local</span>/data/*;</span><br><span class="line"><span class="keyword">do</span> </span><br><span class="line">&gt; y=`<span class="built_in">echo</span> <span class="variable">$x</span> | sed <span class="string">&#x27;s|data|audio_data_utf8|&#x27;</span>`;</span><br><span class="line"><span class="comment"># &gt; echo $y      just preview the output</span></span><br><span class="line"><span class="comment"># &gt; done </span></span><br><span class="line"><span class="comment"># transform all &quot;x&quot; utf16 files into utf8</span></span><br><span class="line">iconv -f UTF-16LE -t UTF-8 <span class="variable">$x</span> &gt; <span class="variable">$y</span>;</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<p><strong>other notes</strong></p>
<p>The liux and windows files are not totally exchangeable, especially when we operate the .txt files on those two different kinds of machines.</p>
<p>especially we can see some codes shows the dissimilarities like: <feff>.</p>
<p>we can use dos2unix tool to do the convertion:<br>After we did wget install dos2unix, then we can just do:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dos2unix the_file_I_want_do_conversion.txt</span><br></pre></td></tr></table></figure>



<h3 id="1-2-2-Text-washing-prepare-the-data"><a href="#1-2-2-Text-washing-prepare-the-data" class="headerlink" title="1.2.2 Text washing(prepare the data)"></a>1.2.2 Text washing(prepare the data)</h3><p>But before we launch the test, we need to firstly do the text washing.</p>
<p>We need to prpare the data and do the data cleaning from the data_path directory<br>def pre_data(data_path):</p>
<h4 id="1-2-2-1-Regular-Expression-this-is-always-the-first-step"><a href="#1-2-2-1-Regular-Expression-this-is-always-the-first-step" class="headerlink" title="1.2.2.1 Regular Expression, this is always the first step"></a>1.2.2.1 Regular Expression, this is always the first step</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">This is core processing function, we mostly use Regular Expression here.</span></span><br><span class="line"><span class="string">Here is just a sample code, that we need to deal with: abrabic numbers, if its number, then there is no need to do segment, just replace it with space one by one. </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">input：&quot;一二三五六&quot;</span></span><br><span class="line"><span class="string">output：&quot;一 二 三 五 六&quot;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">solve_data</span>():</span><br><span class="line">	<span class="comment"># Delete &quot;()&quot;</span></span><br><span class="line">	<span class="comment"># detect Chinese characters(\u4e00-\u9fa5) from a-z, A-Z, 0-9, &quot;.&quot;. It will catch the sentences with those elements.</span></span><br><span class="line">	a = re.findall(<span class="string">&#x27;[\u4e00-\u9fa5a-zA-Z0-9 .]+&#x27;</span>, data, re.S)</span><br><span class="line">	<span class="keyword">return</span> <span class="string">&quot; &quot;</span>.join(a)</span><br><span class="line">	<span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># save the results into a new &quot;solve_data&quot; path</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pre_data</span>(<span class="params">data_path+<span class="string">&quot;solve_data&quot;</span></span>):</span><br><span class="line">	data = []</span><br><span class="line">	<span class="keyword">with</span> <span class="built_in">open</span>(data_path, <span class="string">&quot;w&quot;</span>, encoding=utf-<span class="number">8</span>) <span class="keyword">as</span> file:</span><br><span class="line">		<span class="comment"># loop all the lines</span></span><br><span class="line">		<span class="keyword">for</span> line <span class="keyword">in</span> data:</span><br><span class="line">			file.writelines(<span class="built_in">str</span>(line)+<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">			<span class="keyword">pass</span></span><br><span class="line">		<span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<p>After we get our target, we need to set the processing functions.</p>
<h4 id="1-1-1-2-Replace-numbers-into-words"><a href="#1-1-1-2-Replace-numbers-into-words" class="headerlink" title="1.1.1.2 Replace numbers into words"></a>1.1.1.2 Replace numbers into words</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">replace_num</span>(<span class="params">data</span>)</span><br><span class="line">	data.replace(<span class="string">&quot;.&quot;</span>, <span class="string">&quot;dot&quot;</span>)</span><br><span class="line">	data.replace(<span class="string">&quot;0&quot;</span>, <span class="string">&quot;zero&quot;</span>)</span><br><span class="line">	data.replace(<span class="string">&quot;1&quot;</span>, <span class="string">&quot;one&quot;</span>)</span><br><span class="line">	data.replace(<span class="string">&quot;2&quot;</span>, <span class="string">&quot;two&quot;</span>)</span><br><span class="line">	data.replace(<span class="string">&quot;3&quot;</span>, <span class="string">&quot;three&quot;</span>)</span><br><span class="line">	<span class="comment"># .......	</span></span><br></pre></td></tr></table></figure>

<h4 id="1-1-1-3-Segment"><a href="#1-1-1-3-Segment" class="headerlink" title="1.1.1.3 Segment"></a>1.1.1.3 Segment</h4><p>We need to enterpret the text file to phones, the tools we need is lexicon, which is just like the dictionary. So in this way, we need to segement the words, and according to our prior knowledge from our dictionary, so we can invert the segmented words into the phones. This step is typically used for the language like Chinese, since for Chinese, the word’s stop is not just like we put a space there, but we need to segment it manually. For Chinese, we mostly use Jieba to segement the sentences into words. </p>
<p>Here are the preview of the results should be:<br>input：”今天是一个好日子”<br>output：”今天 是 一个 好 日子”</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line"><span class="comment"># Claim the function for segmenting</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">segment_item</span>(<span class="params">data</span>):</span><br><span class="line">	<span class="keyword">return</span> <span class="string">&quot; &quot;</span>.join(jieba.cut(data))</span><br><span class="line">	<span class="keyword">pass</span></span><br><span class="line"><span class="comment"># After we set this function we can combine into the previous saving files.</span></span><br><span class="line"><span class="comment"># save the file as nosegment </span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(os.join(os.path.join(save_path, <span class="string">&quot;text.nosegement&quot;</span>)), <span class="string">&#x27;w&#x27;</span>, encoding = <span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">	<span class="comment"># loop all the lines and save it one by one.</span></span><br><span class="line">	<span class="keyword">for</span> item <span class="keyword">in</span> text:</span><br><span class="line">		<span class="comment"># we firstly do the segment and then save it one by one</span></span><br><span class="line">		segmet_list = segement_item(item[<span class="number">1</span>])</span><br><span class="line">		file.writelines(item[<span class="number">0</span>] + <span class="string">&quot; &quot;</span> + segmet_list + <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">	<span class="keyword">pass</span> </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="1-1-1-4-Combine-into-a-whole-processing-structure"><a href="#1-1-1-4-Combine-into-a-whole-processing-structure" class="headerlink" title="1.1.1.4 Combine into a whole processing structure"></a>1.1.1.4 Combine into a whole processing structure</h4><p>Now after we did the regular expression and jieba. We just combine them together. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">jieba_cut_data</span>(<span class="params">data</span>):</span><br><span class="line"></span><br><span class="line">	data = replace_num(data)</span><br><span class="line">	<span class="comment"># this is just for the normal case, we just need to cut the sentences</span></span><br><span class="line">	<span class="comment"># cut the words with &quot; &quot; one space, and replace the &quot;  &quot;(two spaces) into only one space.</span></span><br><span class="line">	data = <span class="string">&quot; &quot;</span>.join(jieba.cut(data)).replace(<span class="string">&quot;  &quot;</span>, <span class="string">&quot; &quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="comment"># these are the needs for unusual cases, which we dealt before in the RE section, we already found out the words with those elements we want to handle with. Now, it is time for us to deal with them. If there is all numbers, so we just do not split the words, like &quot;一二三四五&quot;.</span></span><br><span class="line">	is_cut =  <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="comment"># here if the scenario is TRUE, which means there is a element in there, if all are numbers it will become [True, True, True, True, True, ... True, True], in that case, it will be &quot;is_cut&quot; ture. Not in, is not return anymore.</span></span><br><span class="line">	<span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">	input:  这是 学习 笔记</span></span><br><span class="line"><span class="string">	output: [], which is an empty list</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">	input:  这是一本学习笔记本卖两块</span></span><br><span class="line"><span class="string">	output: [  Ture,         True], sum this list we got 2, but not equals to the previous list length, so we do not process it.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">	input:  一二三四五</span></span><br><span class="line"><span class="string">	output: [Ture, Ture, Ture, Ture, True], sum this list we got 5, equals to the previous list length, so we process it.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">	&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> <span class="built_in">sum</span>（[<span class="literal">True</span> <span class="keyword">for</span> item <span class="keyword">in</span> data <span class="keyword">if</span> item <span class="keyword">in</span> [<span class="string">&quot;零&quot;</span>], [<span class="string">&quot;壹&quot;</span>], [<span class="string">&quot;二&quot;</span>], [<span class="string">&quot;三&quot;</span>], [<span class="string">&quot;四&quot;</span>]， [<span class="string">&quot;五&quot;</span>]]）== !<span class="built_in">len</span>(data):</span><br><span class="line">		is_cut = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">	<span class="comment"># here if the scenario is TRUE, not all the context are numbers. we just follow the normal way, cut it with jieba, and replace the two spaces into one space.</span></span><br><span class="line">	<span class="keyword">if</span> is_cut:</span><br><span class="line">		data = <span class="string">&quot; &quot;</span>.join(jieba.cut(data)).replace(<span class="string">&quot;  &quot;</span>, <span class="string">&quot; &quot;</span>))</span><br><span class="line">	<span class="keyword">else</span>：</span><br><span class="line">	<span class="comment"># we process those context with full numbers.</span></span><br><span class="line">	<span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">	input:  一二三四五</span></span><br><span class="line"><span class="string">	output: [一 二 三 四 五]</span></span><br><span class="line"><span class="string">	&#x27;&#x27;&#x27;</span></span><br><span class="line">		data = <span class="string">&quot; &quot;</span>.join(data)</span><br><span class="line">	<span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line">	<span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">data = []</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(data_path, <span class="string">&#x27;r&#x27;</span>, encoding = <span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">	<span class="keyword">for</span> line <span class="keyword">in</span> file.readlines():</span><br><span class="line">		<span class="comment"># print(line.strip(&quot;\n&quot;).strip()), preview the results to delete the &#x27;\n&#x27; together with the space.</span></span><br><span class="line">		<span class="comment"># just append the data that once processed.</span></span><br><span class="line">		<span class="comment"># bef_data here is the before data</span></span><br><span class="line">		bef_data = line.strip(<span class="string">&quot;\n&quot;</span>).strip()</span><br><span class="line">		<span class="comment"># cut the sentences into words</span></span><br><span class="line">		bef_data = <span class="string">&quot; &quot;</span>.join(jieba.cut(bef_data))</span><br><span class="line">		<span class="comment"># here we input the bef_data, after processed in solve_data() function to get the processed data</span></span><br><span class="line">		data.append(solve_data(bef_data))</span><br><span class="line">	<span class="keyword">pass</span></span><br><span class="line"><span class="keyword">pass</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># this is a magic function</span></span><br><span class="line"><span class="keyword">if</span> _name_== <span class="string">&#x27;_main_&#x27;</span>:</span><br><span class="line">	data_path = <span class="string">&quot;./.../.../&quot;</span></span><br><span class="line">	pre_data(data_path)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="1-2-Basic-preparation"><a href="#1-2-Basic-preparation" class="headerlink" title="1.2 Basic preparation"></a>1.2 Basic preparation</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">├── data</span><br><span class="line">│   ├── train</span><br><span class="line">│   │   ├── wav.scp</span><br><span class="line">│   │   ├── text</span><br><span class="line">│   │   ├── utt2spk</span><br><span class="line">│   │   ├── spk2utt</span><br><span class="line">│   ├── test</span><br><span class="line">|── dict</span><br><span class="line">│   ├── lexicon.txt</span><br><span class="line">│   ├── extra_questions.txt</span><br><span class="line">│   ├── nosilence_phones.txt</span><br><span class="line">│   ├── silence_phones.txt</span><br><span class="line">|── lang</span><br><span class="line">│   ├── L.fst/L_disambig.fst</span><br><span class="line">│   ├── oov.int/oov.txt</span><br><span class="line">│   ├── phones.txt</span><br><span class="line">│   ├── topo</span><br><span class="line">│   ├── words.txt</span><br><span class="line">│   ├── phone</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p>This can be how we prepare those files.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [ <span class="variable">$stage</span> -le 1 ];<span class="keyword">then</span></span><br><span class="line">  <span class="built_in">local</span>/thchs-30_data_prep.sh <span class="variable">$thchs</span>/data_thchs30</span><br><span class="line">  <span class="built_in">ln</span> -s <span class="variable">$thchs</span>/data_thchs30 data_thchs30</span><br><span class="line">  <span class="built_in">echo</span> <span class="string">&#x27;###### Bookmark: language preparation ######&#x27;</span></span><br><span class="line">  <span class="comment"># prepare lexicon.txt, extra_questions.txt, nonsilence_phones.txt, optional_silence.txt, silence_phones.txt</span></span><br><span class="line">  <span class="comment"># build a large lexicon that invovles words in both the training and decoding, all in data/dict</span></span><br><span class="line">  <span class="built_in">mkdir</span> -p data/dict;</span><br><span class="line">  <span class="built_in">cp</span> <span class="variable">$thchs</span>/resource/dict/&#123;extra_questions.txt,nonsilence_phones.txt,optional_silence.txt,silence_phones.txt&#125; data/dict &amp;&amp; \</span><br><span class="line">  <span class="built_in">cat</span> <span class="variable">$thchs</span>/resource/dict/lexicon.txt <span class="variable">$thchs</span>/data_thchs30/lm_word/lexicon.txt | \</span><br><span class="line">  grep -v <span class="string">&#x27;&lt;s&gt;&#x27;</span> | grep -v <span class="string">&#x27;&lt;/s&gt;&#x27;</span> | <span class="built_in">sort</span> -u &gt; data/dict/lexicon.txt</span><br><span class="line"></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">&#x27;###### Bookmark: language processing ######&#x27;</span></span><br><span class="line">  <span class="comment"># generate language stuff used for training</span></span><br><span class="line">  <span class="comment"># also lexicon to L_disambig.fst for graph making in local/thchs-30_decode.sh</span></span><br><span class="line">  <span class="built_in">mkdir</span> -p data/lang;</span><br><span class="line">  utils/prepare_lang.sh --position_dependent_phones <span class="literal">false</span> data/dict <span class="string">&quot;&lt;SPOKEN_NOISE&gt;&quot;</span> data/local/lang data/lang</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>





<h3 id="1-2-1-Step-1-Prepare-Train-Files"><a href="#1-2-1-Step-1-Prepare-Train-Files" class="headerlink" title="1.2.1 Step 1. Prepare $Train Files"></a>1.2.1 Step 1. Prepare $Train Files</h3><p>For building those four elements, we need 4 files: <strong>1. wav.scp, 2. text, 3. utt2spk, 4. spk2utt.</strong></p>
<p><img src="/../images/image-20220817041457234.png" alt="image-20220817041457234"></p>
<h4 id="wav-scp"><a href="#wav-scp" class="headerlink" title="wav.scp"></a>wav.scp</h4><p>Here is the format of those 4 files:</p>
<ol>
<li><strong>wav.scp: [audio id] –&gt; [file directory path name]</strong></li>
</ol>
<p>Here are the <code>python</code> way:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment">#The location of the audio directory</span></span><br><span class="line">target_dir = <span class="string">&#x27;./../../&#x27;</span></span><br><span class="line">save_path = <span class="string">&#x27;./../../&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Loop all the audio resources</span></span><br><span class="line">wav_scp = []</span><br><span class="line"><span class="keyword">for</span> file_name <span class="keyword">in</span> os.listdir(target_dir):</span><br><span class="line"><span class="comment"># Append all the .wav file into the list</span></span><br><span class="line">	<span class="keyword">if</span> file_name[-<span class="number">3</span>:<span class="number">0</span>] == <span class="string">&quot;.wav&quot;</span>:</span><br><span class="line"><span class="comment"># Here we use &quot;.&quot; to split the file_name and use join to combine our directory address. We also can use &quot;os.path.join(target_dir + filename)&quot;. </span></span><br><span class="line">		wav_scp.append([file_name.split(<span class="string">&quot;.&quot;</span>)[<span class="number">0</span>], os.path.join(target_dir, filename)])</span><br><span class="line">		<span class="keyword">pass</span></span><br><span class="line">	<span class="keyword">pass</span></span><br><span class="line"><span class="comment"># we can check the output by print(wav_scp)</span></span><br><span class="line"><span class="comment"># Save wav_scp</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(save_path, wav.scp), <span class="string">&#x27;w&#x27;</span>, encoding = <span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line"><span class="comment"># Loop all the items in wav.scp and save them one by one	</span></span><br><span class="line">	<span class="keyword">for</span> item <span class="keyword">in</span> wav.scp: </span><br><span class="line">		file.writelines(item[<span class="number">0</span>]+<span class="string">&quot; &quot;</span>+item[<span class="number">1</span>]+<span class="string">&quot;\n&quot;</span>)   </span><br><span class="line">		<span class="comment">#Our output format should be:  filename target_dir filename</span></span><br><span class="line">	    <span class="keyword">pass</span></span><br><span class="line"><span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<p>The last step can be sorting the file name by vim:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">:sort</span><br></pre></td></tr></table></figure>

<p>The <em>UNIX</em> way:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># find all the wav_files name and their dir</span></span><br><span class="line">find <span class="string">&#x27;./../../&#x27;</span> -iname <span class="string">&#x27;*.wav&#x27;</span> </span><br><span class="line"><span class="comment"># use find we can list all the .wav files&#x27; name, the &quot;i&quot; in &quot;-iname&quot; means not caring the upper or lower case of the characters.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#we can check it by printing the first line </span></span><br><span class="line">find <span class="string">&#x27;./../../&#x27;</span> -iname <span class="string">&#x27;*.wav&#x27;</span> | <span class="built_in">head</span> -n 1</span><br><span class="line"></span><br><span class="line"><span class="comment"># then we can save the .wav file list into a temp place</span></span><br><span class="line">find <span class="string">&#x27;./../../&#x27;</span> -iname <span class="string">&#x27;*.wav&#x27;</span> &gt; wav.scp.temp</span><br><span class="line"></span><br><span class="line"><span class="comment"># now we already got all the uttpath, but we still need the uttid</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cat</span> wav.scp.temp | awk - F <span class="string">&#x27;/&#x27;</span> <span class="string">&#x27;&#123;printf(&quot;%s_%s\n&quot;, $(NF-1), $NF)&#125; &#x27;</span>|sed <span class="string">&#x27;s|.wav||&#x27;</span> &gt; wav_id</span><br><span class="line"><span class="comment"># here we are using sed to remove all the &quot;.wav&quot; strings into &quot; &quot; || means &quot;&quot;, which is empty space</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># we only need to combine the wav.scp.temp and wav_id, since there are all in great orders, so we can just do:</span></span><br><span class="line"><span class="comment"># preview the data: paste -d&#x27; &#x27; wav_id wav.scp.temp | head -n 1</span></span><br><span class="line"><span class="built_in">paste</span> -d<span class="string">&#x27; &#x27;</span> wav_id wav.scp.temp &gt; wav.scp</span><br><span class="line"><span class="comment"># now we can get all the wav.scp</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="Text"><a href="#Text" class="headerlink" title="Text"></a><strong>Text</strong></h4><ol start="2">
<li><strong>text:    audio id –&gt; labelled file</strong></li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">From AUDIOSPK1001.txt get ID and &quot;I Love Kaldi&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">AUDIOSPK1001 I Love Kaldi</span></span><br><span class="line"><span class="string">AUDIOSPK1002 Me too</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">target_dir = <span class="string">&quot;./.../.../&quot;</span></span><br><span class="line"><span class="comment"># This is the stored text file</span></span><br><span class="line"></span><br><span class="line">save_path = <span class="string">&quot;./.../.../&quot;</span></span><br><span class="line">text = []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># loop all the text file name in directory</span></span><br><span class="line"><span class="keyword">for</span> filename <span class="keyword">in</span> os.listdir(target_dir):</span><br><span class="line">	<span class="comment"># only operate the file that ends with &quot;.txt&quot;</span></span><br><span class="line">	<span class="keyword">if</span> filename[-<span class="number">4</span>:] != <span class="string">&quot;.txt&quot;</span>:</span><br><span class="line">		<span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">	<span class="comment"># read the file</span></span><br><span class="line">	<span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(target_dir, filename), <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>)<span class="keyword">as</span> file:</span><br><span class="line">		<span class="comment"># read line by line </span></span><br><span class="line">		<span class="keyword">for</span> line <span class="keyword">in</span> file.readlines():</span><br><span class="line">			<span class="comment"># Delete all &quot;\n&quot; and the the space</span></span><br><span class="line">			line = line.strip(<span class="string">&quot;\n&quot;</span>).strip()</span><br><span class="line">			<span class="comment"># print(line.strip(&quot;\n&quot;)), we can print the text files all in one screen without the \n symbols.</span></span><br><span class="line"></span><br><span class="line">			<span class="comment"># Get the filename with its contents</span></span><br><span class="line">			text.append([filename.split(<span class="string">&quot;.&quot;</span>)[<span class="number">0</span>], line])</span><br><span class="line"></span><br><span class="line">			<span class="keyword">pass</span></span><br><span class="line">		<span class="keyword">pass</span></span><br><span class="line">	<span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># save the file as nosegment </span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(os.join(os.path.join(save_path, <span class="string">&quot;text.nosegement&quot;</span>)), <span class="string">&#x27;w&#x27;</span>, encoding = <span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">	<span class="comment"># loop all the lines and save it one by one.</span></span><br><span class="line">	<span class="keyword">for</span> item <span class="keyword">in</span> text:</span><br><span class="line">		file.writelines(item[<span class="number">0</span>] + <span class="string">&quot; &quot;</span> + item[<span class="number">1</span>] + <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">	<span class="keyword">pass</span> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(text)</span><br></pre></td></tr></table></figure>



<p>At the same time, here are the <em><strong>UNIX</strong></em> way:</p>
<p>we need to get the format like <code>SPK_ID WAV_PATH</code></p>
<p><strong>#AUDIOSPK1001 I Love Kaldi</strong><br><strong>#AUDIOSPK1002 Me too</strong></p>
<p>Here we just create a .sh file called <em>generate_text_id.sh</em></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line">spk_id = <span class="variable">$1</span>  <span class="comment">#$1 is your first variable</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">exit</span> 0;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Then we need to make it into a runable file:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">chmod</span> +x generate_text_id.sh </span><br></pre></td></tr></table></figure>

<p>And then we can run it again:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./generate_text_id.sh SPK.txt</span><br><span class="line"><span class="comment"># it will just print itself</span></span><br><span class="line">SPK.txt</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line">spk_id = <span class="variable">$1</span>  <span class="comment">#$1 is your first variable</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># echo spk_id, this will just print the first column</span></span><br><span class="line">awk &#123;<span class="built_in">printf</span>(<span class="string">&quot;%s %s\n&quot;</span>, <span class="variable">$spk_id</span>, <span class="variable">$1</span>)&#125;<span class="string">&#x27; $spk_id</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">exit 0;</span></span><br></pre></td></tr></table></figure>

<h4 id="utt2spk-audio-id-–-gt-SPK-id"><a href="#utt2spk-audio-id-–-gt-SPK-id" class="headerlink" title="utt2spk: audio id –&gt; SPK id"></a><strong>utt2spk: audio id –&gt; SPK id</strong></h4><h4 id="spk2utt-SPK-–-gt-audio-id"><a href="#spk2utt-SPK-–-gt-audio-id" class="headerlink" title="spk2utt: SPK      –&gt; audio id"></a><strong>spk2utt: SPK      –&gt; audio id</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment"># The path of the audio resources</span></span><br><span class="line">path_dir = <span class="string">&quot;./.../.../&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># The final output path</span></span><br><span class="line">save_path = <span class="string">&quot;./.../.../&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Save the final results</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_data</span>(<span class="params">data, file_name</span>):</span><br><span class="line">	<span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(target_file, file_name), <span class="string">&#x27;w&#x27;</span>, encoding = <span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">		<span class="keyword">for</span> item <span class="keyword">in</span> data:</span><br><span class="line">			<span class="comment"># save the item line in line</span></span><br><span class="line">			file.writelines(item)</span><br><span class="line">			<span class="keyword">pass</span></span><br><span class="line">		<span class="keyword">pass</span></span><br><span class="line">	<span class="keyword">pass</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Audio file name: AUDIOSPK1001.wav</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">	AUDIOSPK1001 SPK1</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_utt2spk</span>():</span><br><span class="line">	<span class="comment"># For saving the final results</span></span><br><span class="line">	utt2spk = [] </span><br><span class="line">	<span class="comment"># loop all the directories</span></span><br><span class="line">	<span class="keyword">for</span> file_name <span class="keyword">in</span> os.listdir(path_dir):</span><br><span class="line">		<span class="comment"># if the file itself is .wav file, we operate, others dismiss</span></span><br><span class="line">		<span class="keyword">if</span> file_name[-<span class="number">4</span>:] == <span class="string">&quot;.wav&quot;</span>:</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">		<span class="comment"># Audio ID</span></span><br><span class="line">		utt = file_name.split(<span class="string">&quot;.&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">		<span class="comment"># SPK ID</span></span><br><span class="line">		spk = utt[-<span class="number">7</span>:-<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line">		<span class="comment"># Print(utt+ &quot; &quot; + spk + &quot;\n&quot;)</span></span><br><span class="line">		<span class="comment"># Add into utt2spk</span></span><br><span class="line">		utt2spk.append(utt + <span class="string">&quot; &quot;</span> + spk + <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">		<span class="keyword">pass</span></span><br><span class="line">	<span class="keyword">pass</span></span><br><span class="line"><span class="comment"># save the data</span></span><br><span class="line">save_data(utt2spk, <span class="string">&quot;utt2spk&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># set the function to get spk2utt</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Audio file name: AUDIOSPK1001.wav</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">	SPK1 AUDIOSPK1001 AUDIOSPK1002</span></span><br><span class="line"><span class="string">	SPK2 AUDIOSPK2001 AUDIOSPK2001</span></span><br><span class="line"><span class="string">	......</span></span><br><span class="line"><span class="string">dict&#123;</span></span><br><span class="line"><span class="string">	&quot;SPK1&quot; : [AUDIOSPK1001, AUDIOSPK1002],</span></span><br><span class="line"><span class="string">	&quot;SPK2&quot; : [AUDIOSPK2001, AUDIOSPK2002],</span></span><br><span class="line"><span class="string">	......</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_spk2utt</span>():</span><br><span class="line">	spk2utt = &#123;&#125;</span><br><span class="line">	<span class="keyword">for</span> file_name <span class="keyword">in</span> os.listdir(path_dir):</span><br><span class="line">		<span class="comment"># Delete a file</span></span><br><span class="line">		<span class="keyword">if</span> file_name[-<span class="number">4</span>:<span class="number">0</span>] == <span class="string">&quot;.txt&quot;</span>:</span><br><span class="line">			<span class="keyword">continue</span></span><br><span class="line">		<span class="comment"># audio ID</span></span><br><span class="line">		utt = file_name.split(<span class="string">&quot;.&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">		<span class="comment"># SPK ID</span></span><br><span class="line">		spk = utt[-<span class="number">7</span>:-<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">		<span class="comment"># If there has a SPK here, we just append</span></span><br><span class="line">		<span class="keyword">if</span> spk <span class="keyword">in</span> spk2utt:</span><br><span class="line">			spk2utt[spk].append(utt)</span><br><span class="line">		<span class="comment"># If there not have a SPK here, we just preset it as a list. </span></span><br><span class="line">		<span class="keyword">else</span>:</span><br><span class="line">			spk2utt[spk] = []</span><br><span class="line">		<span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">		<span class="comment"># using print(spk2utt) to check</span></span><br><span class="line"></span><br><span class="line">		<span class="comment"># final output list from the dict</span></span><br><span class="line">		write_spk2utt = []</span><br><span class="line">		<span class="keyword">for</span> key <span class="keyword">in</span> spk2utt.keys():</span><br><span class="line">			write_spk2utt.append(<span class="built_in">str</span>(key)+<span class="string">&quot; &quot;</span>.join(spk2utt(key))+<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">			<span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">				list = [&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;]</span></span><br><span class="line"><span class="string">				print(&quot; &quot;.join(list))</span></span><br><span class="line"><span class="string">			------------------------------------------------------</span></span><br><span class="line"><span class="string">				A B C D</span></span><br><span class="line"><span class="string">			&#x27;&#x27;&#x27;</span></span><br><span class="line">			<span class="keyword">pass</span></span><br><span class="line">		<span class="comment"># save the output</span></span><br><span class="line">		save_data(write_spk2utt, <span class="string">&quot;spk2utt&quot;</span>)</span><br><span class="line">	<span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">get_spk2utt()</span><br><span class="line">get_utt2spk()</span><br></pre></td></tr></table></figure>

<p>The difference between the utt2spk and the spk2utt is that, for utt2spk, there is only one-to-one relations instead of like spk2utt, there are one-to-multiple relation. So, in most cases, we only need either 3 or 4, because if we already got one, another one is also can be derived.</p>
<h3 id="1-2-2-Step-2-Prepare-Dict-x2F-Dictionary"><a href="#1-2-2-Step-2-Prepare-Dict-x2F-Dictionary" class="headerlink" title="1.2.2 Step 2. Prepare $Dict&#x2F;Dictionary"></a>1.2.2 Step 2. Prepare $Dict&#x2F;Dictionary</h3><p>Dictionary this is the<code> dict</code> file we need to manipulate, in <code>dict</code> directory. The <code> dict</code>  folder can contain these files that we needed:</p>
<p><img src="/../images/image-20220817042227053.png" alt="image-20220817042227053"></p>
<figure class="highlight plaintext"><figcaption><span>includes:</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">#### lexicon.txt : word --&gt; phones</span><br><span class="line"></span><br><span class="line">We need to get the ```lexicon.txt``` by running  ```get_lexicon.py```. </span><br><span class="line"></span><br><span class="line">We need two kinds of dictionaries.</span><br><span class="line">1st. the ```lexicon.txt``` from the corpus to better train a ```n-gram``` model, in some words, the language model.</span><br><span class="line">2st. the word-to-phones, we also need a reference lists from there, we need acoustic model. In this case, so we need a &quot;BIG&quot; dictionary.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">In this step, we need to transform the words into phones, so we can align the words and train them.</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line">	&#x27;&#x27;&#x27;</span><br><span class="line">	This is the dictionary mostly for the acoustic training needs.</span><br><span class="line">	去年  q v4 n ian2</span><br><span class="line">	上去  sh ang4 q v4</span><br><span class="line">	上去  sh ang4 q v5</span><br><span class="line"></span><br><span class="line">	&#x27;&#x27;&#x27;</span><br><span class="line">def get_lexicon(data_path):</span><br><span class="line"></span><br><span class="line">	# set can reduce the duplications. The dictionary must be just a set. </span><br><span class="line">	lexicon = set()</span><br><span class="line">	with open(&quot;data_path&quot;, &quot;w&quot;, encoding = &quot;utf-8&quot;) as file:</span><br><span class="line">		for line in file.readlines():</span><br><span class="line">			#print(line.strip(&quot;\n&quot;).strip().split(&quot; &quot;)), remove the \n and cut with the identifier from the SPACE &quot; &quot;</span><br><span class="line">			[lexicon.add(item) for item in line.strip(&quot;\n&quot;).strip().split(&quot; &quot;)]</span><br><span class="line">	&#x27;&#x27;&#x27;</span><br><span class="line">				input:  这是一本学习笔记本卖两块</span><br><span class="line">				output: [这是，一本， 学习， 笔记本， 卖， 两块],</span><br><span class="line">	&#x27;&#x27;&#x27;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">			pass</span><br><span class="line">		pass</span><br><span class="line">		#print(lexicon)</span><br><span class="line">		# save the lexicon</span><br><span class="line">		with open(&quot;../.../lexicon.txt&quot;, &quot;w&quot;, encoding = &quot;utf-8&quot;) as file:</span><br><span class="line">			for item in lexicon:</span><br><span class="line">				file.writelines(item + &quot;\n&quot;)</span><br><span class="line">		# here are the estimated results.</span><br><span class="line">		&#x27;&#x27;&#x27;</span><br><span class="line">		去年 </span><br><span class="line">		上去  </span><br><span class="line">		上去  </span><br><span class="line">		一</span><br><span class="line">		笔记本</span><br><span class="line">		卖</span><br><span class="line">		&#x27;&#x27;&#x27;</span><br><span class="line">				pass</span><br><span class="line">			pass</span><br><span class="line">	pass</span><br><span class="line"></span><br><span class="line">get_lexicon(&quot;./.../temp&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>




<h4 id="phone-txt-x2F-nonsilence-phones-txt-all-the-phones"><a href="#phone-txt-x2F-nonsilence-phones-txt-all-the-phones" class="headerlink" title="phone.txt&#x2F;nonsilence_phones.txt : all the phones"></a><strong>phone.txt&#x2F;nonsilence_phones.txt : all the phones</strong></h4><h4 id="silence-phones-txt-SIL"><a href="#silence-phones-txt-SIL" class="headerlink" title="silence_phones.txt : SIL"></a>silence_phones.txt : SIL</h4><h4 id="extra-questions-txt"><a href="#extra-questions-txt" class="headerlink" title="extra_questions.txt"></a>extra_questions.txt</h4><p><img src="/../images/image-20220817042905667.png" alt="image-20220817042905667"></p>
<p>The meaning of the <code>extra_questions.txt</code> is to distinguistise the same pronunication with difference tones. This is very important for some tonal languages like Mandarin or Thai…</p>
<p>Finally we can get the ID to words.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ID    [word1, word2, word3, ..., wordn]</span></span><br><span class="line"><span class="string">[&#x27;UDIOSPK1001SEN01&#x27;, &#x27;I, Love, Kaldi&#x27;]</span></span><br><span class="line"><span class="string">[&#x27;UDIOSPK1001SEN02&#x27;, &#x27;Me, too&#x27;]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">id2words</span>(<span class="params">data_path</span>):</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> file_name <span class="keyword">in</span> os.listdir(data_path):</span><br><span class="line">		<span class="keyword">if</span> fiel_name[-<span class="number">3</span>:<span class="number">0</span>] == <span class="string">&quot;txt&quot;</span>:</span><br><span class="line">			<span class="keyword">continue</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">...........</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="1-2-3-Step-3-Prepare-lang"><a href="#1-2-3-Step-3-Prepare-lang" class="headerlink" title="1.2.3 Step 3. Prepare $lang"></a>1.2.3 Step 3. Prepare $lang</h3><p>The <code>lang</code> file is generated from the <code>dict</code>. </p>
<h4 id="L-fst-x2F-L-disambig-fst"><a href="#L-fst-x2F-L-disambig-fst" class="headerlink" title="L.fst&#x2F;L_disambig.fst"></a>L.fst&#x2F;L_disambig.fst</h4><p>Here is the preview of the <code>L.fst</code>. </p>
<p><img src="/../images/image-20220817233820245.png" alt="image-20220817233820245"></p>
<p><img src="/../images/image-20220817233930142.png" alt="image-20220817233930142"></p>
<h4 id="oov-int-x2F-oov-txt"><a href="#oov-int-x2F-oov-txt" class="headerlink" title="oov.int&#x2F;oov.txt"></a>oov.int&#x2F;oov.txt</h4><p>OOv means out of vocabulary, it deals with the words that not in the recognition dictionary. </p>
<h4 id="phones-txt"><a href="#phones-txt" class="headerlink" title="phones.txt"></a>phones.txt</h4><p>Phone.txt gives every phone a number.</p>
<p><img src="/../images/image-20220817233550549.png" alt="image-20220817233550549"></p>
<h4 id="topo"><a href="#topo" class="headerlink" title="topo"></a>topo</h4><p>topo means a hidden markov network.</p>
<p><img src="/../images/image-20220817235807016.png" alt="image-20220817235807016"></p>
<p><img src="/../images/image-20220817235906320.png" alt="image-20220817235906320"></p>
<h4 id="words-txt"><a href="#words-txt" class="headerlink" title="words.txt"></a>words.txt</h4><figure class="highlight plaintext"><figcaption><span>will give each word a number.</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">![image-20220817233522660](../images/image-20220817233522660.png)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#### phone</span><br><span class="line"></span><br><span class="line">```phone``` is a directory, it will help the decision tree to get the clusters. </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 1.4 Acoustic Feature Extractions</span><br><span class="line"></span><br><span class="line">We can have the MFCC feature as well as the ```Fbank``` feature. MFCC is in ```13D```, and ```Fbank``` is ```40D```. </span><br><span class="line"></span><br><span class="line">```sh</span><br><span class="line">if [ $stage -le 2 ];then</span><br><span class="line">  echo &#x27;###### Bookmark: feature extraction ######&#x27;</span><br><span class="line">  # produce MFCC and Fbank features in data/&#123;mfcc,fbank&#125;/&#123;train,test&#125;</span><br><span class="line">  rm -rf data/mfcc &amp;&amp; mkdir -p data/mfcc &amp;&amp; cp -r data/&#123;train,test&#125; data/mfcc</span><br><span class="line">  rm -rf data/fbank &amp;&amp; mkdir -p data/fbank &amp;&amp; cp -r data/&#123;train,test&#125; data/fbank</span><br><span class="line">  for x in train test; do</span><br><span class="line">    # make mfcc and fbank</span><br><span class="line">    steps/make_mfcc.sh --nj $n --cmd &quot;$train_cmd&quot; data/mfcc/$x</span><br><span class="line">    steps/make_fbank.sh --nj $n --cmd &quot;$train_cmd&quot; data/fbank/$x</span><br><span class="line">    # compute cmvn for mfcc and fbank</span><br><span class="line">    steps/compute_cmvn_stats.sh data/mfcc/$x</span><br><span class="line">    steps/compute_cmvn_stats.sh data/fbank/$x</span><br><span class="line">  done</span><br><span class="line">fi</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>The output files in &#96;&#96;&#96;data&#x2F;mfcc&#x2F;train&#96;&#96; can be:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">utt2dur: the duration of each audio file</span><br><span class="line">frame_shift: the frame shit </span><br><span class="line">utt2num_frames: the frame number of the speech</span><br><span class="line">feats.scp: the feature id</span><br><span class="line">cmvn.scp: the cmvn id</span><br><span class="line">data: the feature storage path</span><br><span class="line">log: the log file</span><br></pre></td></tr></table></figure>











<img src="../images/image-20220818000139263.png" alt="image-20220818000139263" style="zoom:80%;" />





<img src="../images/image-20220818000210497.png" alt="image-20220818000210497" style="zoom:80%;" />

<p>MFCC in mostly is used in GMM training, and Fbank used in DNN training, but also there has some experiments to use the high level MFCC features to train the DNN. </p>
<p>Here is the MFCC computing scripts. We can use like <code>allow-downsample</code> or <code>allow-up-sample</code> to help us to do some over or down sampling operations. </p>
<p><img src="/../images/image-20220918005831669.png" alt="image-20220918005831669"></p>
<p>We can view the log files:</p>
<p><img src="/../images/image-20220918010635699.png" alt="image-20220918010635699"></p>
<h2 id="1-5-GMM-Trainning"><a href="#1-5-GMM-Trainning" class="headerlink" title="1.5 GMM Trainning"></a>1.5 GMM Trainning</h2><p>Here we will do the GMM traninings.</p>
<p><img src="/../images/image-20220918005142692.png" alt="image-20220918005142692"></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [ <span class="variable">$stage</span> -le 3 ];<span class="keyword">then</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">&#x27;###### Bookmark: GMM-HMM training ######&#x27;</span></span><br><span class="line">  <span class="comment"># monophone</span></span><br><span class="line">  <span class="comment"># we will train the monophone here.</span></span><br><span class="line">  steps/train_mono.sh --boost-silence 1.25 --nj <span class="variable">$n</span> --cmd <span class="string">&quot;<span class="variable">$train_cmd</span>&quot;</span> data/mfcc/train data/lang exp/mono</span><br><span class="line">  <span class="comment"># monophone ali</span></span><br><span class="line">  <span class="comment"># we will align the monophone to train a GMM-HMM model once again</span></span><br><span class="line">  steps/align_si.sh --boost-silence 1.25 --nj <span class="variable">$n</span> --cmd <span class="string">&quot;<span class="variable">$train_cmd</span>&quot;</span> data/mfcc/train data/lang exp/mono exp/mono_ali</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># the 1.25 here is the default param for setting the silent phone.</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># triphone</span></span><br><span class="line">  <span class="comment"># we will train the monophone here</span></span><br><span class="line">  steps/train_deltas.sh --boost-silence 1.25 --cmd <span class="string">&quot;<span class="variable">$train_cmd</span>&quot;</span> 2000 10000 data/mfcc/train data/lang exp/mono_ali exp/tri1</span><br><span class="line">  <span class="comment"># triphone_ali</span></span><br><span class="line">  <span class="comment"># we will align the triphone to train a GMM-HMM model once again</span></span><br><span class="line">  steps/align_si.sh --nj <span class="variable">$n</span> --cmd <span class="string">&quot;<span class="variable">$train_cmd</span>&quot;</span> data/mfcc/train data/lang exp/tri1 exp/tri1_ali</span><br><span class="line"></span><br><span class="line">  <span class="comment"># lda_mllt</span></span><br><span class="line">  <span class="comment"># we will use the lda_mllt model to do the trainning</span></span><br><span class="line">  steps/train_lda_mllt.sh --cmd <span class="string">&quot;<span class="variable">$train_cmd</span>&quot;</span> --splice-opts <span class="string">&quot;--left-context=3 --right-context=3&quot;</span> 2500 15000 data/mfcc/train data/lang exp/tri1_ali exp/tri2b</span><br><span class="line">  <span class="comment"># lda_mllt_ali</span></span><br><span class="line">  <span class="comment"># realign and retrain</span></span><br><span class="line">  steps/align_si.sh  --nj <span class="variable">$n</span> --cmd <span class="string">&quot;<span class="variable">$train_cmd</span>&quot;</span> --use-graphs <span class="literal">true</span> data/mfcc/train data/lang exp/tri2b exp/tri2b_ali</span><br><span class="line"></span><br><span class="line">  <span class="comment"># sat</span></span><br><span class="line">  steps/train_sat.sh --cmd <span class="string">&quot;<span class="variable">$train_cmd</span>&quot;</span> 2500 15000 data/mfcc/train data/lang exp/tri2b_ali exp/tri3b</span><br><span class="line">  <span class="comment"># sat_ali</span></span><br><span class="line">  steps/align_fmllr.sh --nj <span class="variable">$n</span> --cmd <span class="string">&quot;<span class="variable">$train_cmd</span>&quot;</span> data/mfcc/train data/lang exp/tri3b exp/tri3b_ali</span><br><span class="line"></span><br><span class="line">  <span class="comment"># quick</span></span><br><span class="line">  steps/train_quick.sh --cmd <span class="string">&quot;<span class="variable">$train_cmd</span>&quot;</span> 4200 40000 data/mfcc/train data/lang exp/tri3b_ali exp/tri4b</span><br><span class="line">  <span class="comment"># quick_ali</span></span><br><span class="line">  steps/align_fmllr.sh --nj <span class="variable">$n</span> --cmd <span class="string">&quot;<span class="variable">$train_cmd</span>&quot;</span> data/mfcc/train data/lang exp/tri4b exp/tri4b_ali</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>

<h2 id="1-6-DNN-training"><a href="#1-6-DNN-training" class="headerlink" title="1.6 DNN training"></a>1.6 DNN training</h2><p>Here we will use the <code>TDNN-F (Time Delay Neural Networks Factor)</code> as an example. There are three steps for us to handle this procedure:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [ <span class="variable">$stage</span> -le 4 ];<span class="keyword">then</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">&#x27;###### Bookmark: TDNN-F Chain Training ######&#x27;</span></span><br><span class="line">  <span class="built_in">local</span>/chain/run_tdnn-f_common_skip.sh \</span><br><span class="line">    --mfcc-dir data/mfcc/train --fbank-dir data/fbank/train \</span><br><span class="line">    --gmm-dir exp/tri4b --ali-dir exp/tri4b_ali </span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>

<p>Here are the preview of the <code>run_tdnn-f_common_skip.sh</code> . </p>
<h4 id="1-6-1-Declare-the-Parameters"><a href="#1-6-1-Declare-the-Parameters" class="headerlink" title="1.6.1 Declare the Parameters"></a>1.6.1 Declare the Parameters</h4><p>The first step if to declare the parameters.</p>
<p><img src="/../images/image-20220918153003117.png" alt="image-20220918153003117"></p>
<p>There are some key parameters:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lat_dir: the dir to store the lattice</span><br><span class="line">tree_dir: the dir to store the chain-tree</span><br><span class="line">frames_per_eg: how many frames in each egs, in here it can be 150, 120 or 90</span><br><span class="line">xent_regularize: cross entropy regularization params </span><br></pre></td></tr></table></figure>

<h4 id="1-6-2-Chain-Modeling"><a href="#1-6-2-Chain-Modeling" class="headerlink" title="1.6.2 Chain Modeling"></a>1.6.2 Chain Modeling</h4><p><img src="/../images/image-20220918222909419.png" alt="image-20220918222909419"></p>
<p>This equation shows how we optimize the sequence objects:</p>
<p>$$<br>X : Speech \ Data \<br>W_{r}: The \ real \ transcriptions \<br>\hat{W}: All \ the \ possible \ sequences<br>$$<br>If we look this into anther way, this equation could be:<br>$$<br>F_{MMI} &#x3D; log \frac{lattice}{alignment}<br>$$</p>
<figure class="highlight plaintext"><figcaption><span>in Kaldi, the concept of it is to get the ```one best sequeces``` from different phones at each frame, we dont focus on **each frame's phone** is what, we only care about whether it is more reasonable. So that is the main difference that compared with the pure DNN. **Phones -> Word**</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">![image-20220918161023179](../images/image-20220918161023179.png)</span><br><span class="line"></span><br><span class="line">Here we will send those params into the ```run_chain_common.sh```.</span><br><span class="line"></span><br><span class="line">![image-20220918153441474](../images/image-20220918153441474.png)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">There are three core scripts from the ```run_chain_common.sh```:</span><br><span class="line"></span><br><span class="line">```1. steps/nnet3/chain/gen_topo.py```: It will generate the ```topo``` form files, it has relations with the ```lang``` files. Here are the preview of it. </span><br><span class="line"></span><br><span class="line">![image-20220918155153674](../images/image-20220918155153674.png)</span><br><span class="line"></span><br><span class="line">The upper one is the preview of the common/traditional DNN topo files, the lower one is the ```train``` model generated the new topo files. So as we can see, the second topo files is more **neat**, its in the ```src/hmm-topology.cc``` which is called ```chain TOPO```.  The essence in here is to speed up the tranning and decoding efficiency, since this is why we need a more neat ```TOPO``` structure.  In the ```chain TOPO``` structure, we only need 1 frame, but in the traditional structure, we need 3 frames, this enables us to do the ```frame subsampling```! </span><br><span class="line"></span><br><span class="line">![The left is the traditional DNN topo and right is the Chain Topo](../images/image-20220918222517750.png)</span><br><span class="line"></span><br><span class="line">But also, the ```chain TOPO``` also got a problem like ```over-fitting```. There are three ways to solve the overfitting problem:</span><br><span class="line"></span><br><span class="line">1. xent_regularize: cross entropy regularization</span><br><span class="line"></span><br><span class="line">2. Chain loss &amp; L2 norms</span><br><span class="line"></span><br><span class="line">3. Use leaky HMM factor</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">```2. steps/align_fmllr_lats.sh```: This will generate the lattice ```lat_dir/lat.*.gz``` and alignment ```lat_dir/ali.*.gz```. </span><br><span class="line"></span><br><span class="line">  ![image-20220918155552890](../images/image-20220918155552890.png)</span><br><span class="line"></span><br><span class="line">Here is the previews of ```lat_dir/ali.*.gz```, it will show **each frames corresponds to each phone**, so it is the **frame -&gt; pdf/ phones**. This will be a core part of the **lattice!!!**. </span><br><span class="line"></span><br><span class="line">![image-20220918160141339](../images/image-20220918160141339.png)</span><br><span class="line"></span><br><span class="line">Here are the preview of the ```lattice```: Here, the ```0``` node can be the ```Node id1```, the ```1``` node can be ```Node id2```, the output will be the ```word id```, the cost can be the sum of ```AM score``` + ```LM score```, the ```transid 1-A``` means the word frame length is from 1~A. It can be a very informative ```alignment files```. The input is the ```transid 1-A```, output will be the ```word id```. </span><br><span class="line"></span><br><span class="line">```3. steps/nnet3/chain/build_tree.sh```: The output will be a new ```tree_dir/tree```. Here is the preview of the decision tree:</span><br><span class="line"></span><br><span class="line">![image-20220918160819553](../images/image-20220918160819553.png) </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">![image-20220918224419611](../images/image-20220918224419611.png)</span><br><span class="line"></span><br><span class="line">Here is what ```TDNN-F``` looks like:</span><br><span class="line"></span><br><span class="line">![image-20220918225055235](../images/image-20220918225055235.png)</span><br><span class="line"></span><br><span class="line">The ```linear_opts``` is the core param of the ```TDNN-F```, if without this param it will only be the ``TDNN`` model without ```f```.  As shown from the code,. it will apply in the whole ```layer trainning```.</span><br><span class="line"></span><br><span class="line">#### 1.6.3 Trainning</span><br><span class="line"></span><br><span class="line">Here we got to the chain model trainning part. </span><br><span class="line"></span><br><span class="line">![image-20220918230042243](../images/image-20220918230042243.png)</span><br><span class="line"></span><br><span class="line">The train step is very similar to the most of the DNN trainnings, the difference is that it will generate the ```phone_lm``` and ```den(denominator).fst```.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 2. Language Model and Decoding: WFST &quot;The Big Four&quot; </span><br><span class="line"></span><br><span class="line">![image-20220817214614445](../images/image-20220817214614445.png)</span><br><span class="line"></span><br><span class="line">![image-20220918230913656](../images/image-20220918230913656.png)</span><br><span class="line"></span><br><span class="line">From the last chapter we already knew ```HCLG.fst``` includes ```H.fst```, ```C.fst```, ```L.fst```, ```G.fs```.  Here is a tutorial doc from: https://nadirapovey.blogspot.com/2021/12/what-is-hclgfst.html to explain what is HCLG.</span><br><span class="line"></span><br><span class="line">![image-20220918230610030](../images/image-20220918230610030.png)</span><br><span class="line"></span><br><span class="line">Here are the flowchart: from ```acoustic characteristics ---&gt; phones ---&gt; words ---&gt; sentences```.</span><br><span class="line"></span><br><span class="line">```H.fst``` enables us to input the acoustics characteritics and return the phone.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">**L.fst enables us to input phones to word.**</span><br><span class="line"></span><br><span class="line">How to get those four files can be the core idea of the kaldi ASR system. The ASR detection logic can be: ```acoustic features --&gt; H.fst --&gt; phones C.fst --&gt; L.fst + G.fst (linguistics) --&gt; words```.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 2.1 H.fst (HMM States)</span><br><span class="line"></span><br><span class="line">For H.fst, what we want is input the acoustic characteristics, output pdf/phones.</span><br><span class="line"></span><br><span class="line">### 2.1.1 Make MFCC</span><br><span class="line"></span><br><span class="line">After we run this script below, the Kaldi will automatically generate 7 files:</span><br><span class="line"></span><br><span class="line">```Bash</span><br><span class="line">steps/make_mfcc.sh --nj 1 --mfcc-config=/root/data/kaldi_file/</span><br></pre></td></tr></table></figure>

<ol>
<li>conf: default param</li>
<li>data: the MFCC output, just like feats.scp</li>
<li>feats.scp  </li>
<li>frame_shift</li>
<li>log：some log files generated</li>
<li>utt2dur</li>
<li>utt2num_frames</li>
</ol>
<h4 id="2-1-1-1-feats-scp"><a href="#2-1-1-1-feats-scp" class="headerlink" title="2.1.1.1 feats.scp"></a>2.1.1.1 feats.scp</h4><p>The format of it can be like:</p>
<p><em>AUDIO_FILE_ID    Location_Directory_of_the_MFCC_Generated_in_AWK</em></p>
<p>The significance of this file is to tell us where the MFCC will be stored. All the MFCC features will be stored at AWK formats. AWK is binary forms, because it will save the space. </p>
<p>This is the preview of 13th MFCC: </p>
<p>AUDIO_ID</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[54.32323 -12.8887 -2.12212  3.2322 ... -2.323232  #13th features for each frame</span><br><span class="line"></span><br><span class="line">4.323323 -11.5887 -3.12312   8.2422 ... -4.323239</span><br><span class="line"></span><br><span class="line">5.332324 -10.8877 -6.442212  3.2322 ... -7.223132 ]</span><br></pre></td></tr></table></figure>

<h4 id="2-1-1-2-frame-shift"><a href="#2-1-1-2-frame-shift" class="headerlink" title="2.1.1.2 frame_shift"></a>2.1.1.2 frame_shift</h4><p>The frame shift is just a param told us the frame shift time, if it is 10ms, then it will print 0.01, since 10ms &#x3D; 0.01s.</p>
<h4 id="2-1-1-3-utt2dur"><a href="#2-1-1-3-utt2dur" class="headerlink" title="2.1.1.3 utt2dur"></a>2.1.1.3 utt2dur</h4><p>This will show us every audio files’ durations.</p>
<p><em>AUDIO_FILE_ID      #Durations (s)</em></p>
<h4 id="2-1-1-4-utt2num-frames"><a href="#2-1-1-4-utt2num-frames" class="headerlink" title="2.1.1.4 utt2num_frames"></a>2.1.1.4 utt2num_frames</h4><p>This will told us every audio files’ frame numbers. Since we already know frame_shift time is 0.01s. Which means for every frame it needs 0.01s.</p>
<p><em>AUDIO_FILE_ID      #Number of frames</em></p>
<h4 id="2-1-5-visualize-ark-file"><a href="#2-1-5-visualize-ark-file" class="headerlink" title="2.1.5 visualize ark file"></a>2.1.5 visualize ark file</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">copy-feats ark:cmvn_kaldi_file.ark ark, t:cmvn_feat.ark.txt</span><br></pre></td></tr></table></figure>

<p>Here is how we visualize the ark file into the txt. After that we can preview the cmvn_ark.txt file.</p>
<p><img src="/../images/image-20220818000941498.png" alt="image-20220818000941498"></p>
<h3 id="2-1-2-CMVN"><a href="#2-1-2-CMVN" class="headerlink" title="2.1.2 CMVN"></a>2.1.2 CMVN</h3><p>This operation is for solving one problem which is that we need to take into the different people’s diversities. Since we knew that for different people have different timbre. <code>CMVN</code> is for solving this problem.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">egs/wsj/steps/compute_cmvn_stats.sh &lt;data_dir&gt;</span><br></pre></td></tr></table></figure>

<p>The following is where the <code>CMVN</code> tool belongs to. </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">steps/compute_cmvn_stats.sh ./kaldi_file</span><br></pre></td></tr></table></figure>

<p>Here we generated the <code>CMVN</code> in the kaldi_file directory. </p>
<p>After we visualized the <code>.ark</code> file from the kaidi_file directory to preview the <code>.txt</code> file.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">copy-feats ark:cmvn_kaldi_file.ark ark, t:cmvn_feat.ark.txt</span><br></pre></td></tr></table></figure>

<p><img src="/../images/image-20220918010545144.png" alt="image-20220918010545144"></p>
<p>We can know that for each frame, there have 13D MFCC params, so if we need to do CMVN, we need to caculate 2 params for each frame. So there will be every column has two params: average and variation. So there had 13 columns, so for each column we need 13*2 &#x3D; 26 CMVN params, which consists 13 averg and 13 var.</p>
<p>If we do not caring about the SPK, just focus on the audio content itslelf will be a big issue. Since as we know, we do need know the spk’s voice characteristics and this will affect our trainings,we need to take that bias into it. We will do “CMVN” here, this will be applied for prior distribution for male and female. The value between the “CMVN” is [0-1]. </p>
<h3 id="2-1-3-Generate-H-fst"><a href="#2-1-3-Generate-H-fst" class="headerlink" title="2.1.3 Generate H.fst"></a>2.1.3 Generate H.fst</h3><p> After we got <code>CMVN</code>, we already can generate the <code>H.fst</code> file. </p>
<h3 id="2-1-4-Check-Log"><a href="#2-1-4-Check-Log" class="headerlink" title="2.1.4 Check Log"></a>2.1.4 Check Log</h3><p><img src="/../images/image-20220818001112500.png" alt="image-20220818001112500"></p>
<h2 id="2-2-L-fst-Lexicon-x2F-Dictionary"><a href="#2-2-L-fst-Lexicon-x2F-Dictionary" class="headerlink" title="2.2 L.fst (Lexicon&#x2F;Dictionary)"></a>2.2 L.fst (Lexicon&#x2F;Dictionary)</h2><p>We input phones and output words. </p>
<p>Generate <code>run.sh &amp; get L.fst</code></p>
<p>The final step should be write a <code>run.sh</code> file to generate the <code>L.fst</code> file.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. generate the L.fst</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># here we used prepare_lang.sh </span></span><br><span class="line"><span class="comment"># there are four params we input: </span></span><br><span class="line"></span><br><span class="line"><span class="comment">#	1. the four files we prepared, fix_data_dir.sh ./local/dict</span></span><br><span class="line"><span class="comment">#   2. If there has the phones not in the dictionary, what it will be recognized as &#x27;SIL&#x27;</span></span><br><span class="line"><span class="comment">#   3. the temp files</span></span><br><span class="line"><span class="comment">#   4. F.fst</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">utils/prepare_lang.sh ./local/dict <span class="string">&#x27;SIL&#x27;</span> ./temp/01/ L/lang</span><br></pre></td></tr></table></figure>

<h3 id="Visualize-the-L-fst-file"><a href="#Visualize-the-L-fst-file" class="headerlink" title="Visualize the L.fst file"></a>Visualize the L.fst file</h3><p>we can print the .fst here to see the whole results.</p>
<img src="../images/image-20220817233710490.png" alt="image-20220817233710490" style="zoom:80%;" />

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fstprint ../lang/L.fst</span><br></pre></td></tr></table></figure>

<p>Or we can just check the first 20th results:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fstprint ../lang/L.fst | <span class="built_in">head</span> -n 20</span><br></pre></td></tr></table></figure>

<p>Save the log of the L.fst into L.txt.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fstprint ../lang/L.fst &gt; L.txt</span><br></pre></td></tr></table></figure>

<p>After we generated the L.fst, we can get the estimation from there. All the phones and words will get an ID. </p>
<p>  phone_ID   word_ID     input: phone    output: word    probabilities<br>    0           1        	<eps>    		<eps>   	  0.6878887788<br>    1           2        	EY1_S      		  A           0.7987897897<br>  …..<br>Here are the .fst format: </p>
<p>We can use fstdraw to draw the decoding graph.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fstdraw --isymbols=../lang/phones.txt --osymbols=../lang/words.txt ../lang/L.fst  &gt; L.dot</span><br></pre></td></tr></table></figure>

<p>We can firstly output a L.dot file then we can just draw it. So we can use .dot file to generate it into a jpg file.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">apt wget install ghostscript</span><br><span class="line">apt wget install graphviz</span><br><span class="line">dot -Tjpg L.dot &gt; L.jpg</span><br></pre></td></tr></table></figure>

<h2 id="2-3-C-fst-（Context）"><a href="#2-3-C-fst-（Context）" class="headerlink" title="2.3. C.fst （Context）"></a>2.3. C.fst （Context）</h2><p>In here, means the phones can be affected by the phones next to it</p>
<p>Input phones and output phones.  Its optional in Kaldi when we make the <code>HCLG.fst</code>. </p>
<h2 id="2-4-G-fst-just-n-gram-get-lm-sh-Language-Model"><a href="#2-4-G-fst-just-n-gram-get-lm-sh-Language-Model" class="headerlink" title="2.4 G.fst : just n-gram  get_lm.sh (Language Model)"></a>2.4 G.fst : just n-gram  get_lm.sh (Language Model)</h2><p>we can download <code>srilm</code>. </p>
<p>Language model is very easy, we just need to prepare the corpus line by line and make sure cutted the sentences.</p>
<figure class="highlight plaintext"><figcaption><span>actually is ```G.fsa```, ```fsa``` is a very typical kind of fst, it is a kind of reciever, which inputs equals to output.</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">```Python</span><br><span class="line"># the name can be set as: text.lm</span><br><span class="line"></span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line"></span><br><span class="line">[word1, word2, word3, ..., wordn]</span><br><span class="line">[&#x27;I, Love, Kaldi&#x27;]</span><br><span class="line">[&#x27;Me, too&#x27;]</span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Here we just introduce <code>UNIX</code> way to do it. We will use <code>awk</code>. </p>
<figure class="highlight plaintext"><figcaption><span>is very fast then python, if there is efficiency needs.</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">```Python</span><br><span class="line"># get the corpus input we need to process </span><br><span class="line">file_name = &#x27;/root/data/.../...&#x27; </span><br><span class="line"></span><br><span class="line"># read the file</span><br><span class="line">with open(file_name, &#x27;r&#x27;, encoding = &#x27;utf-8&#x27;) as file:</span><br><span class="line">	for item in file.readlines():</span><br><span class="line">		print(&quot; &quot;.join(item.strip(&quot;\n&quot;)strip().split(&quot; &quot;)[1:]))</span><br><span class="line">		pass</span><br><span class="line">	pass</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># we can just get [word1, word2, word3, ..., wordn]</span><br></pre></td></tr></table></figure>

<p>We will use the <code>AWK</code> to do the same thing.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># here are the original idea</span></span><br><span class="line"><span class="comment">#[AUDIOSPK1001 &#x27;I, Love, Kaldi&#x27;]</span></span><br><span class="line"><span class="comment">#[AUDIOSPK1001 &#x27;Me, too&#x27;]</span></span><br><span class="line"><span class="comment"># we can just firstly test it with print in awk</span></span><br><span class="line">awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> text <span class="comment"># here &quot;text&quot; means the txt file you want to manipulate, her is $1 means we print the first colum. It will look like:</span></span><br><span class="line"><span class="comment"># AUDIOSPK1001</span></span><br><span class="line"><span class="comment"># AUDIOSPK1002</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># If is $0, which means the whole. $2 means the second column. $4 is the fourth column.</span></span><br></pre></td></tr></table></figure>


<p>Here we need to get the column that except the first column.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">awk <span class="string">&#x27;&#123;for(i=2; i&lt;NF; i++) printf $i &quot;\t&quot;; printf &#x27;</span>\n<span class="string">&#x27;&#125;&#x27;</span> text <span class="comment"># here the \t is just like \n,  we can delete it as well. the default diving symbol is &#x27; &#x27;, in here actually awk -F &#x27; &#x27;&#x27;&#123;for(i=2; i&lt;NF; i++) printf $i &quot;\t&quot;; printf &#x27;\n&#x27;&#125;&#x27; text. NF is the last column, awk is based on column manipulations. </span></span><br><span class="line"></span><br><span class="line">awk <span class="string">&#x27;&#123;for(i=2; i&lt;NF; i++) printf $i &quot;&quot;; printf &#x27;</span>\n<span class="string">&#x27;&#125;&#x27;</span> text</span><br><span class="line"><span class="comment"># we will get exactly the same output just like python, but much faster:</span></span><br><span class="line"><span class="comment"># word1, word2, word3, ..., wordn</span></span><br><span class="line"><span class="comment"># I, Love, Kaldi</span></span><br><span class="line"><span class="comment"># Me, too</span></span><br></pre></td></tr></table></figure>

<h3 id="2-4-1-write-get-lm-sh-we-need-to-write-aw-shell-script-to-run-and-get-th-lm-language-model"><a href="#2-4-1-write-get-lm-sh-we-need-to-write-aw-shell-script-to-run-and-get-th-lm-language-model" class="headerlink" title="2.4.1 write get_lm.sh (we need to write aw shell script to run and get th lm(language model))"></a>2.4.1 write get_lm.sh (we need to write aw shell script to run and get th lm(language model))</h3><figure class="highlight plaintext"><figcaption><span>language model is statistical language model, more tranning data can be more "better" in some ways.</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">```Bash</span><br><span class="line"># You need firstly specify your corpus sources.</span><br><span class="line">text = &quot;./text.lm&quot;</span><br><span class="line"># 1. get all the corpus</span><br><span class="line"># awk &#x27;&#123;for(i=2; i&lt;NF; i++) printf $i &quot;&quot;; printf &#x27;\n&#x27;&#125;&#x27; text &gt; xxx.lm</span><br><span class="line"># loop all the columns:</span><br><span class="line">#	NF here means the last column</span><br><span class="line">#   printf just like C language, they are the same in some ways</span><br><span class="line"># 2. Deploy Trigram n-gram model</span><br><span class="line">ngram-count -text text.lm -order 3 write train.part.txt.count  </span><br><span class="line"># OR we can use</span><br><span class="line">ngram-count -text $text -order 3 write train.part.txt.count  </span><br><span class="line"># $text means the file itself, we already defined it at first.</span><br><span class="line"># -text: the corpus</span><br><span class="line"># wirte: write the file</span><br><span class="line"># here 3 means tri, which indicates triphone, and write into train.part.txt.count file.</span><br><span class="line"># here are the preview</span><br><span class="line"></span><br><span class="line">#   word  pairs         times</span><br><span class="line">#      I                  10</span><br><span class="line">#    I  Love              5</span><br><span class="line">#  I  Love Kaldi          1</span><br><span class="line">#  Hello World &lt;/s&gt;       2</span><br><span class="line">#  &lt;/s&gt; is great          1</span><br><span class="line"># &lt;/s&gt; means the starting or ending point, usually means something will begin or end from there.  </span><br><span class="line"></span><br><span class="line"># 3. From the 2nd step,  generateing the lm</span><br><span class="line">ngram-count -read train.part.txt.count -order 3 -lm LM -interpole -kndiscount</span><br><span class="line">#  -lm which means the generated Language Model, right now we call it LM</span><br><span class="line"># -interpole is the smoothing function, and kndiscount is the callback function.There are two possibilities, one is the original and other which is callback function.</span><br><span class="line">#  \data\</span><br><span class="line"># ngram 1 = 2821      , here means there are 2821 1grams&#x27; pairs</span><br><span class="line"># ngram 2 = 6344</span><br><span class="line"># ngram 3 = 444</span><br><span class="line"># \1-grams:</span><br><span class="line"># -3.4234324     1       -0.034523532 this is also probabities but with log(), we call backoff method</span><br><span class="line"># -3.4234224     2       -0.032323532</span><br><span class="line"># -2.3234224     A       -0.023233532</span><br><span class="line"># \2-grams:</span><br><span class="line"># -3.2424432     I  Love          -0.232312332</span><br><span class="line"># \3-grams:</span><br><span class="line"># -4.3244343     I  Love Kaldi    -0.454554545</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="2-4-2-Generate-G-fst"><a href="#2-4-2-Generate-G-fst" class="headerlink" title="2.4.2 Generate G.fst"></a>2.4.2 Generate G.fst</h3><p>There has two ways to generate <code>G.fst</code>.</p>
<p>Way1: Just Call from the Kaldi shell</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">utils/format_lm_sri.sh data/lang /lm/LM /data/local/dict/lexicon.txt/data/lang_test</span><br></pre></td></tr></table></figure>

<p>Way2: using <code>arpa2fst</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arpa2fst --disambig-symbol=<span class="comment">#0 --read-symbol-table=/data/lang/words.txt /lm/LM/G.fst</span></span><br></pre></td></tr></table></figure>



<h1 id="5-Decoder"><a href="#5-Decoder" class="headerlink" title="5. Decoder"></a>5. Decoder</h1><p>In Kaldi, we decode the <code>HCLG.fst</code>, <code>HCLG</code> is just a kind of fst graph, it will use the <code>Viterbi</code> to decode. That is the easiest way to decode the fst model. </p>
<h2 id="5-1-GMM-latgen-faster-Decoder"><a href="#5-1-GMM-latgen-faster-Decoder" class="headerlink" title="5.1 GMM-latgen-faster Decoder"></a>5.1 GMM-latgen-faster Decoder</h2><p>We can use the default decoder to decode the files. <code>GMM-latgen-faster</code> decoder can be thought as one type of <code>LatticeSimpleDecoder</code>.</p>
<p><img src="/../images/image-20220918230959696.png" alt="image-20220918230959696"></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">decode decode.sh --nj 1 ./exp/mono/graph ./data/ ./exp/mono/decode</span><br></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># this is the basic params it need</span></span><br><span class="line">steps/decode.sh [option] &lt;graph-dir&gt; &lt;data-dir&gt; &lt;decode-dir&gt;</span><br><span class="line"><span class="comment"># &lt;graph-dir&gt; is the HCLG.fst</span></span><br><span class="line"><span class="comment"># &lt;data-dir&gt; is the data files needed to be decode</span></span><br><span class="line"><span class="comment"># &lt;decode-dir&gt; is the results Kaldi ASR should output</span></span><br></pre></td></tr></table></figure>

<p>After the Kaldi did the decoding, it will calculate <code>WER</code> (1-ER) for us. </p>
<h2 id="5-2-Simple-Decoder"><a href="#5-2-Simple-Decoder" class="headerlink" title="5.2 Simple Decoder"></a>5.2 Simple Decoder</h2><figure class="highlight plaintext"><figcaption><span>Decoder```: If we would like to use the ```gmm-decode-simple```, we need to follow the following scripts:</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">```sh</span><br><span class="line">model=&quot;.../final.mdl&quot;   # we need to specify the </span><br><span class="line">hclg= &quot;.../HCLG.fst&quot;</span><br><span class="line">feats= &quot;cmvn.scp&quot; # the acoustics fatures</span><br><span class="line">out= &quot;.&quot; # the output file</span><br><span class="line"></span><br><span class="line"># we need to apply the cmvn into the acoustic features: feats.scp</span><br><span class="line">apply-cmvn --utt2spk=ark:$&#123;feats&#125;/utt2spk scp:$&#123;feats&#125;/cmvn.scp scp:$&#123;feats&#125;/feats.scp ark, t:- |add-deltas ark:- ark:feats_cmvn_delta.ark</span><br><span class="line"></span><br><span class="line">gmm-decode-simple $&#123;model&#125; $&#123;hclg&#125; ark:feats_cmvn_delta.ark ark,t:$&#123;out&#125;</span><br></pre></td></tr></table></figure>

<h2 id="5-3-Faster-Decoder"><a href="#5-3-Faster-Decoder" class="headerlink" title="5.3 Faster Decoder"></a>5.3 Faster Decoder</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model=<span class="string">&quot;.../final.mdl&quot;</span>   <span class="comment"># we need to specify the </span></span><br><span class="line">hclg= <span class="string">&quot;.../HCLG.fst&quot;</span></span><br><span class="line">feats= <span class="string">&quot;cmvn.scp&quot;</span> <span class="comment"># the acoustics fatures</span></span><br><span class="line">out= <span class="string">&quot;./result_faster&quot;</span> <span class="comment"># the output file</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">gmm-decode-faster <span class="variable">$&#123;model&#125;</span> <span class="variable">$&#123;hclg&#125;</span> ark:feats_cmvn_delta.ark ark,t:<span class="variable">$&#123;out&#125;</span></span><br></pre></td></tr></table></figure>

<p>We can make the fast decoder just this way.</p>
<h3 id="5-4-NN-Decoding"><a href="#5-4-NN-Decoding" class="headerlink" title="5.4 NN Decoding"></a>5.4 NN Decoding</h3><p><img src="/../images/image-20220918231119689.png" alt="image-20220918231119689"></p>
<h1 id="6-A-Very-Short-Demo"><a href="#6-A-Very-Short-Demo" class="headerlink" title="6. A Very Short Demo"></a>6. A Very Short Demo</h1><p>In this part we will download and train a complete kaldi ASR demo from installation to decoding. Since the installation of kaldi is too big and also there has a lot of submodules we do not really need. So in this case, we just do some file modifications, we just make a mini-version in order to better understand the kaldi workflow and study.</p>
<p>Here is a tutorial from Nadira Povey: <a target="_blank" rel="noopener" href="https://nadirapovey.blogspot.com/2022/05/librispeech-training.html">https://nadirapovey.blogspot.com/2022/05/librispeech-training.html</a></p>
<p>Firstly, we need to download the kaldi demo from the git:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/xiao11lam/kaldi_tutorials.git</span><br><span class="line">cd kaldi_tutorials</span><br><span class="line"># change the write and read privilege</span><br><span class="line">chmod -R 755  ./*</span><br></pre></td></tr></table></figure>

<p>Here is a <code>repo</code> only for the tutorial purposes, since we have manipulated some files from the original Kaldi in order to make the installation and training process more friendly.</p>
<p><strong>And remember before you start to make this demo, please make sure you already have the cuda installed!!!.</strong></p>
<p>We highly suggesting you use the kaldi installation shell scripts written from the <code>AssemblyAI</code> <a target="_blank" rel="noopener" href="https://www.assemblyai.com/blog/kaldi-install-for-dummies/">https://www.assemblyai.com/blog/kaldi-install-for-dummies/</a></p>
<p>Please follow the instructions step by steps.</p>
<p><img src="/../images/image-20220817231038503.png" alt="image-20220817231038503"></p>
<h2 id="1-Set-the-Tools-Environment"><a href="#1-Set-the-Tools-Environment" class="headerlink" title="1. Set the Tools Environment"></a>1. Set the Tools Environment</h2><p>Check the CPU info, to find out how many processors your PC have.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep <span class="string">&#x27;processor&#x27;</span> /proc/cpuinfo | <span class="built_in">sort</span> -u | <span class="built_in">wc</span> -l</span><br></pre></td></tr></table></figure>

<p><img src="/../images/image-20220731104820116.png" alt="image-20220731104820116"></p>
<p>Now I got <code>8</code>.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /mnt/c/Users/ABC/Desktop/kaldi-cslt/tools</span><br><span class="line">vim run.sh  <span class="comment"># check the env installation scripts</span></span><br><span class="line">sh run.sh <span class="comment"># we can just run the scripts and let it automatically install</span></span><br></pre></td></tr></table></figure>

<p>Here are the preview of the <code>run.sh</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># here you can spefify your CPU info</span></span><br><span class="line">make -j 8</span><br><span class="line"><span class="comment"># install the IRSTLM</span></span><br><span class="line">./extras/install_irstlm.sh</span><br><span class="line"><span class="comment"># The env.sh is not under tools/extras/. It is under tools/.So you need to change the environmental variable.</span></span><br><span class="line"><span class="built_in">source</span> env.sh</span><br><span class="line"><span class="comment"># install the openblas</span></span><br><span class="line">./extras/install_openblas.sh</span><br></pre></td></tr></table></figure>



<h2 id="2-Set-the-Src-Environment"><a href="#2-Set-the-Src-Environment" class="headerlink" title="2. Set the Src Environment"></a>2. Set the Src Environment</h2><p>Here, we follow the same way to install these <code>src</code> environments.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /mnt/c/Users/ABC/Desktop/kaldi-cslt/src</span><br><span class="line">vim run.sh  <span class="comment"># modify the run.sh file if you want (optional)</span></span><br><span class="line">sh run.sh</span><br></pre></td></tr></table></figure>

<p>Here are the preview of the <code>run.sh</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">./configure --static \</span><br><span class="line">      --use-cuda=<span class="built_in">yes</span> --cudatk-dir=/usr/local/cuda \</span><br><span class="line">      --mathlib=OPENBLAS --openblas-root=../tools/OpenBLAS/install \</span><br><span class="line">      --static-math=<span class="built_in">yes</span> \</span><br><span class="line">      --static-fst=<span class="built_in">yes</span> --fst-root=../tools/openfst</span><br><span class="line"></span><br><span class="line">make depend -j 40</span><br><span class="line"></span><br><span class="line">make -j 40</span><br></pre></td></tr></table></figure>



<h2 id="3-Prepare-for-the-Acoustic-Model-AM"><a href="#3-Prepare-for-the-Acoustic-Model-AM" class="headerlink" title="3. Prepare for the Acoustic Model (AM)"></a>3. Prepare for the Acoustic Model (AM)</h2><p>Finally, we will get into the <code>egs</code> dir to firstly train an acoustic model.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /kaldi_tutorials/egs/thchs30</span><br><span class="line">vim run_am.sh</span><br><span class="line">sh run_am.sh  <span class="comment"># start to train the AM</span></span><br></pre></td></tr></table></figure>

<p>Here we need to change the path into the our local database directory:</p>
<p><img src="/../images/image-20220731194754537.png" alt="image-20220731194754537"></p>
<p><img src="/../images/image-20220731211958212.png" alt="image-20220731211958212"></p>
<p>Here are the step to step code for <code>run_am.sh</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Copyright 2016  Tsinghua University (Author: Dong Wang, Xuewei Zhang)</span></span><br><span class="line"><span class="comment">#           2018  Tsinghua University (Author: Zhiyuan Tang)</span></span><br><span class="line"><span class="comment">#           2019  Tsinghua University (Author: Wenqiang Du)</span></span><br><span class="line"><span class="comment">#           2022  Sirui Li Zixi Yan </span></span><br><span class="line"><span class="comment"># Apache 2.0.</span></span><br><span class="line"></span><br><span class="line">. ./cmd.sh <span class="comment">## You&#x27;ll want to change cmd.sh to something that will work on your system.</span></span><br><span class="line">           <span class="comment">## This relates to the queue.</span></span><br><span class="line">. ./path.sh</span><br><span class="line"></span><br><span class="line">n=10 <span class="comment"># parallel jobs</span></span><br><span class="line">stage=-4</span><br><span class="line"><span class="built_in">set</span> -euo pipefail <span class="comment"># This command sets any pipeline command to stop if there is an error or an undefined method variable.</span></span><br><span class="line"><span class="comment"># at present, kaldi supports python 2</span></span><br><span class="line">py_ver=`python -c <span class="string">&#x27;import sys; v, _, _, _, _= sys.version_info;  print(&quot;%d&quot; % v)&#x27;</span>`</span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$py_ver</span> -gt 2 ]; <span class="keyword">then</span> <span class="built_in">echo</span> <span class="string">&quot;Python version should be 2 (now <span class="variable">$py_ver</span>)&quot;</span>; <span class="built_in">exit</span> 1; <span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;###### Bookmark: basic preparation ######&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># corpus and trans directory</span></span><br><span class="line">thchs=/work105/duwenqiang/data/ <span class="comment"># Data path, the path where the downloaded thchs data archive will be stored after decompression</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#you can obtain the database by uncommting the following lines</span></span><br><span class="line"><span class="comment">#[ -d $thchs ] || mkdir -p $thchs  || exit 1</span></span><br><span class="line"><span class="comment">#echo &quot;downloading THCHS30 at $thchs ...&quot;</span></span><br><span class="line"><span class="comment">#local/download_and_untar.sh $thchs  http://www.openslr.org/resources/18 data_thchs30  || exit 1</span></span><br><span class="line"><span class="comment">#local/download_and_untar.sh $thchs  http://www.openslr.org/resources/18 resource      || exit 1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$stage</span> -le 1 ];<span class="keyword">then</span></span><br><span class="line">  <span class="built_in">local</span>/thchs-30_data_prep.sh <span class="variable">$thchs</span>/data_thchs30 <span class="comment">#This is the code written for thchs30 data, can not be directly applied to other data, the scripts in the local folder are prepared for the current data, not applicable to other data</span></span><br><span class="line"></span><br><span class="line">  <span class="built_in">ln</span> -s <span class="variable">$thchs</span>/data_thchs30 data_thchs30 <span class="comment">#This is a soft link to call the language model in the folder later</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">&#x27;###### Bookmark: language preparation ######&#x27;</span></span><br><span class="line">  <span class="comment"># prepare lexicon.txt, extra_questions.txt, nonsilence_phones.txt, optional_silence.txt, silence_phones.txt</span></span><br><span class="line">  <span class="comment"># build a large lexicon that invovles words in both the training and decoding, all in data/dict</span></span><br><span class="line">  <span class="built_in">mkdir</span> -p data/dict; </span><br><span class="line">  <span class="built_in">cp</span> <span class="variable">$thchs</span>/resource/dict/&#123;extra_questions.txt,nonsilence_phones.txt,optional_silence.txt,silence_phones.txt&#125; data/dict &amp;&amp; \</span><br><span class="line">  <span class="built_in">cat</span> <span class="variable">$thchs</span>/resource/dict/lexicon.txt <span class="variable">$thchs</span>/data_thchs30/lm_word/lexicon.txt | \</span><br><span class="line">  grep -v <span class="string">&#x27;&lt;s&gt;&#x27;</span> | grep -v <span class="string">&#x27;&lt;/s&gt;&#x27;</span> | <span class="built_in">sort</span> -u &gt; data/dict/lexicon.txt</span><br><span class="line"></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">&#x27;###### Bookmark: language processing ######&#x27;</span></span><br><span class="line">  <span class="comment"># generate language stuff used for training</span></span><br><span class="line">  <span class="comment"># also lexicon to L_disambig.fst for graph making in local/thchs-30_decode.sh</span></span><br><span class="line">  <span class="built_in">mkdir</span> -p data/lang;</span><br><span class="line">  utils/prepare_lang.sh --position_dependent_phones <span class="literal">false</span> data/dict <span class="string">&quot;&lt;SPOKEN_NOISE&gt;&quot;</span> data/local/lang data/lang</span><br><span class="line"></span><br><span class="line"><span class="keyword">fi</span> </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$stage</span> -le 2 ];<span class="keyword">then</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">&#x27;###### Bookmark: feature extraction ######&#x27;</span></span><br><span class="line">  <span class="comment"># produce MFCC and Fbank features in data/&#123;mfcc,fbank&#125;/&#123;train,test&#125;</span></span><br><span class="line">  <span class="built_in">rm</span> -rf data/mfcc &amp;&amp; <span class="built_in">mkdir</span> -p data/mfcc &amp;&amp; <span class="built_in">cp</span> -r data/&#123;train,<span class="built_in">test</span>&#125; data/mfcc</span><br><span class="line">  <span class="built_in">rm</span> -rf data/fbank &amp;&amp; <span class="built_in">mkdir</span> -p data/fbank &amp;&amp; <span class="built_in">cp</span> -r data/&#123;train,<span class="built_in">test</span>&#125; data/fbank</span><br><span class="line">  <span class="keyword">for</span> x <span class="keyword">in</span> train <span class="built_in">test</span>; <span class="keyword">do</span></span><br><span class="line">    <span class="comment"># make mfcc and fbank</span></span><br><span class="line">    steps/make_mfcc.sh --nj <span class="variable">$n</span> --cmd <span class="string">&quot;<span class="variable">$train_cmd</span>&quot;</span> data/mfcc/<span class="variable">$x</span></span><br><span class="line">    <span class="comment"># extract mfcc features --nj is how many threads to use to extract features, the number of threads should be less than the number of lines in spk2utt</span></span><br><span class="line">    steps/make_fbank.sh --nj <span class="variable">$n</span> --cmd <span class="string">&quot;<span class="variable">$train_cmd</span>&quot;</span> data/fbank/<span class="variable">$x</span></span><br><span class="line">    <span class="comment">#Extraction of fbank features</span></span><br><span class="line">    <span class="comment"># compute cmvn</span></span><br><span class="line">    steps/compute_cmvn_stats.sh data/mfcc/<span class="variable">$x</span> <span class="comment">#The mean and variance of mfcc features are done, and the mean-variance can improve the performance of the model to some extent.</span></span><br><span class="line">    steps/compute_cmvn_stats.sh data/fbank/<span class="variable">$x</span></span><br><span class="line">  <span class="keyword">done</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$stage</span> -le 3 ];<span class="keyword">then</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">&#x27;###### Bookmark: GMM-HMM training ######&#x27;</span></span><br><span class="line">  <span class="comment"># monophone</span></span><br><span class="line">  <span class="comment"># Train the monophonic model, this step will generate a model file of num.mdl under exp/mono/ when completed and link the final generated num.mdl to final.mdl.</span></span><br><span class="line">  steps/train_mono.sh --boost-silence 1.25 --nj <span class="variable">$n</span> --cmd <span class="string">&quot;<span class="variable">$train_cmd</span>&quot;</span> data/mfcc/train data/lang exp/mono</span><br><span class="line">  <span class="comment"># monophone ali</span></span><br><span class="line">  steps/align_si.sh --boost-silence 1.25 --nj <span class="variable">$n</span> --cmd <span class="string">&quot;<span class="variable">$train_cmd</span>&quot;</span> data/mfcc/train data/lang exp/mono exp/mono_ali</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># triphone</span></span><br><span class="line">  <span class="comment">#Training the three-phoneme model.</span></span><br><span class="line">  <span class="comment">#2000 10000 specify the number of states and Gaussians respectively</span></span><br><span class="line">  <span class="comment">#input is data/mfcc/train data/lang exp/mono_ali, training data, lang files, alignment files</span></span><br><span class="line">  <span class="comment">#output is stored in tri1, mainly mdl model files and some alignment files</span></span><br><span class="line">  steps/train_deltas.sh --boost-silence 1.25 --cmd <span class="string">&quot;<span class="variable">$train_cmd</span>&quot;</span> 2000 10000 data/mfcc/train data/lang exp/mono_ali exp/tri1</span><br><span class="line">  <span class="comment"># triphone_ali</span></span><br><span class="line">  <span class="comment">#Caculate the alignment info</span></span><br><span class="line">  steps/align_si.sh --nj <span class="variable">$n</span> --cmd <span class="string">&quot;<span class="variable">$train_cmd</span>&quot;</span> data/mfcc/train data/lang exp/tri1 exp/tri1_ali</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># lda_mllt</span></span><br><span class="line">  <span class="comment"># Input features are transformed with LDA+MLLT features and then trained with a three-phoneme model</span></span><br><span class="line">  steps/train_lda_mllt.sh --cmd <span class="string">&quot;<span class="variable">$train_cmd</span>&quot;</span> --splice-opts <span class="string">&quot;--left-context=3 --right-context=3&quot;</span> 2500 15000 data/mfcc/train data/lang exp/tri1_ali exp/tri2b</span><br><span class="line">  <span class="comment"># lda_mllt_ali</span></span><br><span class="line">  steps/align_si.sh  --nj <span class="variable">$n</span> --cmd <span class="string">&quot;<span class="variable">$train_cmd</span>&quot;</span> --use-graphs <span class="literal">true</span> data/mfcc/train data/lang exp/tri2b exp/tri2b_ali</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># sat</span></span><br><span class="line">  <span class="comment"># Training speaker adaptation models using FMLLR (for speaker-specific feature transformation)</span></span><br><span class="line">  steps/train_sat.sh --cmd <span class="string">&quot;<span class="variable">$train_cmd</span>&quot;</span> 2500 15000 data/mfcc/train data/lang exp/tri2b_ali exp/tri3b</span><br><span class="line">  <span class="comment"># sat_ali</span></span><br><span class="line">  steps/align_fmllr.sh --nj <span class="variable">$n</span> --cmd <span class="string">&quot;<span class="variable">$train_cmd</span>&quot;</span> data/mfcc/train data/lang exp/tri3b exp/tri3b_ali</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># quick</span></span><br><span class="line">  steps/train_quick.sh --cmd <span class="string">&quot;<span class="variable">$train_cmd</span>&quot;</span> 4200 40000 data/mfcc/train data/lang exp/tri3b_ali exp/tri4b</span><br><span class="line">  <span class="comment"># quick_ali</span></span><br><span class="line">  steps/align_fmllr.sh --nj <span class="variable">$n</span> --cmd <span class="string">&quot;<span class="variable">$train_cmd</span>&quot;</span> data/mfcc/train data/lang exp/tri4b exp/tri4b_ali</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$stage</span> -le 4 ];<span class="keyword">then</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">&#x27;###### Bookmark: TDNN-F Chain Training ######&#x27;</span></span><br><span class="line">  <span class="built_in">local</span>/chain/run_tdnn-f_common_skip.sh \</span><br><span class="line">    --mfcc-dir data/mfcc/train --fbank-dir data/fbank/train \</span><br><span class="line">    --gmm-dir exp/tri4b --ali-dir exp/tri4b_ali </span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="4-Prepare-for-the-Language-Model-LM"><a href="#4-Prepare-for-the-Language-Model-LM" class="headerlink" title="4. Prepare for the Language Model (LM)"></a>4. Prepare for the Language Model (LM)</h2><p>This is the <code>run_lm.sh</code> file. </p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">dir</span>=exp/lm </span><br><span class="line">lm_dir=  <span class="comment"># the dir to store the LM</span></span><br><span class="line">gmm_mdl_dir=exp/tri4b <span class="comment"># the place to store the gmm</span></span><br><span class="line">nn_mdl_dir=exp/chain-skip/tdnn-f-cn <span class="comment"># the chain model dir</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">mkdir</span> <span class="variable">$dir</span></span><br><span class="line"><span class="comment"># compress the language model from the open resource data_thchs30</span></span><br><span class="line">tar czvf <span class="variable">$dir</span>/corpus.lm_e-7.tar.gz  data_thchs30/lm_word/word.3gram.lm</span><br><span class="line"><span class="comment"># transform the language model into G.fst</span></span><br><span class="line">./utils/format_lm.sh  data/lang <span class="variable">$dir</span>/corpus.lm_e-7.tar.gz  data/lang <span class="variable">$dir</span>/lang_test</span><br><span class="line"><span class="comment"># make the GMM acoustic model&#x27;s lang files to compose with the G.fst into HCLG.fst</span></span><br><span class="line">./utils/mkgraph.sh   <span class="variable">$dir</span>/lang_test <span class="variable">$gmm_mdl_dir</span>  <span class="variable">$gmm_mdl_dir</span>/graph</span><br><span class="line"><span class="comment"># compose the chain model, lang files, and G.fst into the HCLG.fst</span></span><br><span class="line">./utils/mkgraph.sh  --self-loop-scale 1.0 <span class="variable">$dir</span>/lang_test <span class="variable">$nn_mdl_dir</span>  <span class="variable">$nn_mdl_dir</span>/graph</span><br></pre></td></tr></table></figure>





<h2 id="5-Decode"><a href="#5-Decode" class="headerlink" title="5. Decode"></a>5. Decode</h2><p>We will use the <code>./decode_chain.sh</code>, it will print the <code>WER</code>. </p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">. ./path.sh</span><br><span class="line">. ./cmd.sh</span><br><span class="line">exp_dir=exp/chain-skip/tdnn-f-cn <span class="comment"># the AM and the storage path</span></span><br><span class="line">beam=13 <span class="comment"># the threshold of the beam search, the bigger the beam the seach time will be longer and vice versa</span></span><br><span class="line">stage=-3</span><br><span class="line"><span class="keyword">for</span> data_set <span class="keyword">in</span> <span class="built_in">test</span>  ;<span class="keyword">do</span> <span class="comment"># test corpus</span></span><br><span class="line">      steps/nnet3/decode.sh \</span><br><span class="line">      --nj 8 --acwt 1.0 --post-decode-acwt 10.0 \ <span class="comment"># the decoding params</span></span><br><span class="line">      --cmd <span class="string">&quot;run.pl&quot;</span> --iter final \ <span class="comment"># use final.mdl to decode</span></span><br><span class="line">      --stage <span class="variable">$stage</span> \</span><br><span class="line">      <span class="variable">$exp_dir</span>/graph  data/fbank/<span class="variable">$data_set</span> <span class="variable">$exp_dir</span>/decode_graph_final</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="built_in">cat</span> <span class="variable">$exp_dir</span>/decode_graph_final/scoring_kaldi/best_wer <span class="comment"># check the decoding results</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#result: %WER 21.75 [ 17647 / 81139, 149 ins, 664 del, 16834 sub ] exp/chain-skip/tdnn-f-cn/decode_graph_final/wer_10_0.0</span></span><br></pre></td></tr></table></figure>









<h1 id="7-Kaldi-Vad"><a href="#7-Kaldi-Vad" class="headerlink" title="7. Kaldi Vad"></a>7. Kaldi Vad</h1><h2 id="compute-vad-decision-sh"><a href="#compute-vad-decision-sh" class="headerlink" title="compute_vad_decision.sh"></a>compute_vad_decision.sh</h2><p>We can find the <code>compute_vad_decision.sh</code> in <code>kaldi-egs/wsj/s5/steps/compute_vad_decision.sh</code>.</p>
<h1 id="8-Some-Useful-Tools-in-Kaldi"><a href="#8-Some-Useful-Tools-in-Kaldi" class="headerlink" title="8. Some Useful Tools in Kaldi"></a>8. Some Useful Tools in Kaldi</h1><h2 id="8-1-utils-x2F-run-pl"><a href="#8-1-utils-x2F-run-pl" class="headerlink" title="8.1 utils&#x2F;run.pl"></a>8.1 utils&#x2F;run.pl</h2><p>This will help the Kaldi run the system in multiple processing units，which makes the kaldi training more fast. We will discuss the <code>nj</code> later, since we will know <code>num_jobs</code>.</p>
<p>There is a very important tips here is that:</p>
<p>the <code>nj</code> value should smaller than the corpus speaker’s number. If there are 20 speakers in your corpus, you cannot set that number higher than that. If not follow this rule, it will send the errors.</p>
<h2 id="8-2-split-data-sh"><a href="#8-2-split-data-sh" class="headerlink" title="8.2 split_data.sh"></a>8.2 split_data.sh</h2><p>It will cut the data directories. </p>
<h1 id="9-Some-Useful-Links"><a href="#9-Some-Useful-Links" class="headerlink" title="9. Some Useful Links"></a>9. Some Useful Links</h1><p><a target="_blank" rel="noopener" href="https://www.eleanorchodroff.com/tutorial/kaldi/training-acoustic-models.html">https://www.eleanorchodroff.com/tutorial/kaldi/training-acoustic-models.html</a></p>
<p><a target="_blank" rel="noopener" href="https://faculty.sbs.arizona.edu/hammond/ling578-sp20/">https://faculty.sbs.arizona.edu/hammond/ling578-sp20/</a></p>
<p><a target="_blank" rel="noopener" href="https://shichaog1.gitbooks.io/hand-book-of-speech-enhancement-and-recognition/content/">https://shichaog1.gitbooks.io/hand-book-of-speech-enhancement-and-recognition/content/</a></p>
<p><a target="_blank" rel="noopener" href="https://desh2608.github.io/2020-05-18-using-librispeech/">https://desh2608.github.io/2020-05-18-using-librispeech/</a></p>
<p><a target="_blank" rel="noopener" href="http://jrmeyer.github.io/asr/2016/01/26/Installing-Kaldi.html">http://jrmeyer.github.io/asr/2016/01/26/Installing-Kaldi.html</a></p>
<p>Understanding kaldi recipes with mini-librispeech example: <a target="_blank" rel="noopener" href="https://medium.com/@qianhwan/understanding-kaldi-recipes-with-mini-librispeech-example-part-1-hmm-models-472a7f4a0488">https://medium.com/@qianhwan/understanding-kaldi-recipes-with-mini-librispeech-example-part-1-hmm-models-472a7f4a0488</a></p>
<p><a target="_blank" rel="noopener" href="https://www.assemblyai.com/blog/kaldi-speech-recognition-for-beginners-a-simple-tutorial/">https://www.assemblyai.com/blog/kaldi-speech-recognition-for-beginners-a-simple-tutorial/</a></p>
<p><a target="_blank" rel="noopener" href="http://pelhans.com/2018/01/18/kaldi-note1/">http://pelhans.com/2018/01/18/kaldi-note1/</a></p>

</div>


<style>
  .portfolio-content img {
    width: 100%;      /* Make the image width equal to the container width */
    height: auto;     /* Maintain the aspect ratio */
    max-width: 100%;  /* Ensures the image does not exceed the container width */
  }
</style>





      </div>
      
  	</div>

    <!-- After footer scripts -->
    <script src="https://code.jquery.com/jquery-3.1.1.slim.min.js" integrity="sha384-A7FZj7v+d/sdmMqp/nOQwliLvUsJfDHW+k9Omg/a/EheAdgtzNs3hpfag6Ed950n" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tether/1.4.0/js/tether.min.js" integrity="sha384-DztdAPBWPRXSA/3eYEEUWrWCy7G5KFbe8fFjk5JAIxUYHKkDx6Qin1DkWx51bBrb" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/js/bootstrap.min.js" integrity="sha384-vBWWzlZJ8ea9aCX4pEW3rVHjgjt7zpkNpZk+02D9phzyeVkE+jo0ieGizqPLForn" crossorigin="anonymous"></script>

  </body>
</html>
